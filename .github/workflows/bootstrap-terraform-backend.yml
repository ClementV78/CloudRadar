name: bootstrap-terraform-backend

on:
  workflow_dispatch:
    inputs:
      region:
        description: "AWS region for backend resources"
        required: true
        default: "us-east-1"
      state_bucket_name:
        description: "S3 bucket name for Terraform state (must be globally unique)"
        required: true
      lock_table_name:
        description: "DynamoDB table name for Terraform locks"
        required: true
        default: "cloudradar-tf-lock"
      backup_bucket_name:
        description: "Optional S3 bucket name for SQLite backups"
        required: false
      aircraft_reference_bucket_name:
        description: "Optional S3 bucket name for aircraft reference data artifacts"
        required: false
      dns_zone_name:
        description: "Optional Route53 hosted zone name for delegated subdomain (e.g., cloudradar.example.com)"
        required: false
      issue_tls:
        description: "Issue a public TLS certificate with Let's Encrypt DNS-01 and store it in SSM"
        required: false
        type: boolean
        default: false
      tls_domain:
        description: "TLS domain to issue (required when issue_tls=true, e.g., cloudradar.example.com)"
        required: false
      role_arn:
        description: "Optional role ARN to assume (defaults to AWS_TERRAFORM_ROLE_ARN variable)"
        required: false

permissions:
  id-token: write
  contents: read

jobs:
  bootstrap:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          # Prefer explicit input, fallback to repo variable.
          role-to-assume: ${{ inputs.role_arn || vars.AWS_TERRAFORM_ROLE_ARN }}
          # Inputs are required, but keep fallback in case defaults change.
          aws-region: ${{ inputs.region || vars.AWS_REGION }}

      - name: Terraform init (local backend)
        run: terraform -chdir=infra/aws/bootstrap init -backend=false

      - name: Resolve backend inputs
        run: |
          set -euo pipefail
          STATE_BUCKET="${{ inputs.state_bucket_name || vars.TF_STATE_BUCKET }}"
          LOCK_TABLE="${{ inputs.lock_table_name || vars.TF_LOCK_TABLE_NAME }}"
          BACKUP_BUCKET="${{ inputs.backup_bucket_name || vars.TF_BACKUP_BUCKET_NAME }}"
          AIRCRAFT_REFERENCE_BUCKET="${{ inputs.aircraft_reference_bucket_name || vars.TF_AIRCRAFT_REFERENCE_BUCKET_NAME }}"
          DNS_ZONE_NAME="${{ inputs.dns_zone_name || vars.DNS_ZONE_NAME }}"
          ISSUE_TLS="${{ inputs.issue_tls }}"
          TLS_DOMAIN="${{ inputs.tls_domain }}"

          {
            echo "STATE_BUCKET=${STATE_BUCKET}"
            echo "LOCK_TABLE=${LOCK_TABLE}"
            echo "ISSUE_TLS=${ISSUE_TLS}"
            echo "TLS_DOMAIN=${TLS_DOMAIN}"
            echo "TF_VAR_state_bucket_name=${STATE_BUCKET}"
            echo "TF_VAR_lock_table_name=${LOCK_TABLE}"
            echo "TF_VAR_region=${{ inputs.region || vars.AWS_REGION }}"
          } >> "${GITHUB_ENV}"

          if [[ -n "${BACKUP_BUCKET}" ]]; then
            {
              echo "BACKUP_BUCKET=${BACKUP_BUCKET}"
              echo "TF_VAR_backup_bucket_name=${BACKUP_BUCKET}"
            } >> "${GITHUB_ENV}"
          fi

          if [[ -n "${AIRCRAFT_REFERENCE_BUCKET}" ]]; then
            {
              echo "AIRCRAFT_REFERENCE_BUCKET=${AIRCRAFT_REFERENCE_BUCKET}"
              echo "TF_VAR_aircraft_reference_bucket_name=${AIRCRAFT_REFERENCE_BUCKET}"
            } >> "${GITHUB_ENV}"
          fi

          if [[ -n "${DNS_ZONE_NAME}" ]]; then
            {
              echo "DNS_ZONE_NAME=${DNS_ZONE_NAME}"
              echo "TF_VAR_dns_zone_name=${DNS_ZONE_NAME}"
            } >> "${GITHUB_ENV}"
          fi

      - name: Import existing backend resources (idempotent)
        run: |
          set -euo pipefail
          STATE_BUCKET="${STATE_BUCKET}"
          LOCK_TABLE="${LOCK_TABLE}"
          BACKUP_BUCKET="${BACKUP_BUCKET:-}"
          AIRCRAFT_REFERENCE_BUCKET="${AIRCRAFT_REFERENCE_BUCKET:-}"
          DNS_ZONE_NAME="${DNS_ZONE_NAME:-}"

          if aws s3api head-bucket --bucket "${STATE_BUCKET}" >/dev/null 2>&1; then
            terraform -chdir=infra/aws/bootstrap import aws_s3_bucket.tf_state "${STATE_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import aws_s3_bucket_versioning.tf_state "${STATE_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import aws_s3_bucket_server_side_encryption_configuration.tf_state "${STATE_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import aws_s3_bucket_public_access_block.tf_state "${STATE_BUCKET}"
          fi

          if aws dynamodb describe-table --table-name "${LOCK_TABLE}" >/dev/null 2>&1; then
            terraform -chdir=infra/aws/bootstrap import aws_dynamodb_table.tf_lock "${LOCK_TABLE}"
          fi

          if [[ -n "${BACKUP_BUCKET}" ]] && aws s3api head-bucket --bucket "${BACKUP_BUCKET}" >/dev/null 2>&1; then
            terraform -chdir=infra/aws/bootstrap import module.sqlite_backups[0].aws_s3_bucket.this "${BACKUP_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import module.sqlite_backups[0].aws_s3_bucket_versioning.this "${BACKUP_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import module.sqlite_backups[0].aws_s3_bucket_server_side_encryption_configuration.this "${BACKUP_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import module.sqlite_backups[0].aws_s3_bucket_public_access_block.this "${BACKUP_BUCKET}"
          fi

          if [[ -n "${AIRCRAFT_REFERENCE_BUCKET}" ]] && aws s3api head-bucket --bucket "${AIRCRAFT_REFERENCE_BUCKET}" >/dev/null 2>&1; then
            terraform -chdir=infra/aws/bootstrap import module.aircraft_reference[0].aws_s3_bucket.this "${AIRCRAFT_REFERENCE_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import module.aircraft_reference[0].aws_s3_bucket_versioning.this "${AIRCRAFT_REFERENCE_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import module.aircraft_reference[0].aws_s3_bucket_server_side_encryption_configuration.this "${AIRCRAFT_REFERENCE_BUCKET}"
            terraform -chdir=infra/aws/bootstrap import module.aircraft_reference[0].aws_s3_bucket_public_access_block.this "${AIRCRAFT_REFERENCE_BUCKET}"
          fi

          if [[ -n "${DNS_ZONE_NAME}" ]]; then
            # Import the hosted zone by name when it already exists, so reruns are safe.
            ZONE_ID="$(aws route53 list-hosted-zones-by-name \
              --dns-name "${DNS_ZONE_NAME}." \
              --output json | jq -r --arg name "${DNS_ZONE_NAME}." '.HostedZones[] | select(.Name==$name) | .Id' | head -n1)"
            ZONE_ID="${ZONE_ID##*/}"

            if [[ -n "${ZONE_ID}" && "${ZONE_ID}" != "null" ]]; then
              terraform -chdir=infra/aws/bootstrap import aws_route53_zone.cloudradar[0] "${ZONE_ID}"
            fi
          fi

      - name: Terraform apply (create backend)
        run: |
          # Use local backend on runner to avoid a chicken-and-egg dependency.
          BACKUP_BUCKET="${BACKUP_BUCKET:-}"
          AIRCRAFT_REFERENCE_BUCKET="${AIRCRAFT_REFERENCE_BUCKET:-}"
          DNS_ZONE_NAME="${DNS_ZONE_NAME:-}"

          APPLY_ARGS=(
            "-var=region=${{ inputs.region || vars.AWS_REGION }}"
            "-var=state_bucket_name=${STATE_BUCKET}"
            "-var=lock_table_name=${LOCK_TABLE}"
          )

          if [[ -n "${BACKUP_BUCKET}" ]]; then
            APPLY_ARGS+=("-var=backup_bucket_name=${BACKUP_BUCKET}")
          fi

          if [[ -n "${AIRCRAFT_REFERENCE_BUCKET}" ]]; then
            APPLY_ARGS+=("-var=aircraft_reference_bucket_name=${AIRCRAFT_REFERENCE_BUCKET}")
          fi

          if [[ -n "${DNS_ZONE_NAME}" ]]; then
            APPLY_ARGS+=("-var=dns_zone_name=${DNS_ZONE_NAME}")
          fi

          terraform -chdir=infra/aws/bootstrap apply -auto-approve "${APPLY_ARGS[@]}"

      - name: Validate TLS issue inputs
        if: ${{ inputs.issue_tls }}
        run: |
          set -euo pipefail
          if [[ -z "${TLS_DOMAIN}" ]]; then
            echo "tls_domain is required when issue_tls=true" >&2
            exit 1
          fi
          if [[ -z "${DNS_ZONE_NAME:-}" ]]; then
            echo "dns_zone_name (input or DNS_ZONE_NAME variable) is required when issue_tls=true" >&2
            exit 1
          fi

          DNS_ZONE_NO_DOT="${DNS_ZONE_NAME%.}"
          if [[ "${TLS_DOMAIN}" != "${DNS_ZONE_NO_DOT}" && "${TLS_DOMAIN}" != *".${DNS_ZONE_NO_DOT}" ]]; then
            echo "tls_domain (${TLS_DOMAIN}) must be within dns_zone_name (${DNS_ZONE_NO_DOT})" >&2
            exit 1
          fi

      - name: Validate existing TLS parameters when issue_tls=false
        if: ${{ !inputs.issue_tls }}
        env:
          TLS_FULLCHAIN_PARAM: /cloudradar/edge/tls/fullchain_pem
          TLS_PRIVKEY_PARAM: /cloudradar/edge/tls/privkey_pem
        run: |
          set -euo pipefail
          CERT_PATH="$(mktemp)"
          KEY_PATH="$(mktemp)"
          trap 'rm -f "${CERT_PATH}" "${KEY_PATH}"' EXIT

          aws ssm get-parameter \
            --name "${TLS_FULLCHAIN_PARAM}" \
            --with-decryption \
            --query 'Parameter.Value' \
            --output text > "${CERT_PATH}"

          aws ssm get-parameter \
            --name "${TLS_PRIVKEY_PARAM}" \
            --with-decryption \
            --query 'Parameter.Value' \
            --output text > "${KEY_PATH}"

          # Fail fast if no valid certificate is present while TLS issuance is not requested.
          openssl x509 -in "${CERT_PATH}" -noout -checkend 0 >/dev/null
          cert_modulus_md5="$(openssl x509 -in "${CERT_PATH}" -noout -modulus | openssl md5)"
          key_modulus_md5="$(openssl rsa -in "${KEY_PATH}" -noout -modulus | openssl md5)"
          if [[ "${cert_modulus_md5}" != "${key_modulus_md5}" ]]; then
            echo "Existing SSM TLS certificate and private key do not match." >&2
            exit 1
          fi

      - name: Install certbot DNS Route53 plugin
        if: ${{ inputs.issue_tls }}
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y certbot python3-certbot-dns-route53

      - name: Issue TLS certificate and store in SSM Parameter Store
        if: ${{ inputs.issue_tls }}
        env:
          TLS_FULLCHAIN_PARAM: /cloudradar/edge/tls/fullchain_pem
          TLS_PRIVKEY_PARAM: /cloudradar/edge/tls/privkey_pem
          TLS_METADATA_PARAM: /cloudradar/edge/tls/metadata
        run: |
          set -euo pipefail

          CERTBOT_DIR="$(mktemp -d)"
          trap 'rm -rf "${CERTBOT_DIR}"' EXIT

          certbot certonly \
            --non-interactive \
            --agree-tos \
            --register-unsafely-without-email \
            --dns-route53 \
            --key-type rsa \
            --rsa-key-size 2048 \
            --config-dir "${CERTBOT_DIR}/config" \
            --work-dir "${CERTBOT_DIR}/work" \
            --logs-dir "${CERTBOT_DIR}/logs" \
            -d "${TLS_DOMAIN}"

          FULLCHAIN_PATH="${CERTBOT_DIR}/config/live/${TLS_DOMAIN}/fullchain.pem"
          PRIVKEY_PATH="${CERTBOT_DIR}/config/live/${TLS_DOMAIN}/privkey.pem"

          if [[ ! -s "${FULLCHAIN_PATH}" || ! -s "${PRIVKEY_PATH}" ]]; then
            echo "Certificate issuance succeeded but expected cert/key files are missing." >&2
            exit 1
          fi

          put_secure_parameter_with_tier_fallback() {
            local param_name="$1"
            local source_file="$2"
            local param_value
            local stderr_file
            stderr_file="$(mktemp)"
            param_value="$(cat "${source_file}")"

            if aws ssm put-parameter \
              --name "${param_name}" \
              --type SecureString \
              --tier Standard \
              --overwrite \
              --value "${param_value}" \
              >/dev/null 2>"${stderr_file}"; then
              echo "Stored ${param_name} as SecureString (Standard tier)."
              rm -f "${stderr_file}"
              return 0
            fi

            if grep -Eiq "Standard parameters may have values with a maximum size of 4096|ValidationException|size" "${stderr_file}"; then
              aws ssm put-parameter \
                --name "${param_name}" \
                --type SecureString \
                --tier Advanced \
                --overwrite \
                --value "${param_value}" \
                >/dev/null
              echo "Stored ${param_name} as SecureString (Advanced tier fallback)."
              rm -f "${stderr_file}"
              return 0
            fi

            echo "Failed storing ${param_name}." >&2
            cat "${stderr_file}" >&2
            rm -f "${stderr_file}"
            return 1
          }

          put_secure_parameter_with_tier_fallback "${TLS_FULLCHAIN_PARAM}" "${FULLCHAIN_PATH}"
          put_secure_parameter_with_tier_fallback "${TLS_PRIVKEY_PARAM}" "${PRIVKEY_PATH}"

          NOT_AFTER="$(openssl x509 -in "${FULLCHAIN_PATH}" -noout -enddate | cut -d= -f2-)"
          FINGERPRINT_SHA256="$(openssl x509 -in "${FULLCHAIN_PATH}" -noout -fingerprint -sha256 | cut -d= -f2)"
          ISSUED_AT_UTC="$(date -u +%Y-%m-%dT%H:%M:%SZ)"

          METADATA_JSON="$(jq -cn \
            --arg domain "${TLS_DOMAIN}" \
            --arg not_after "${NOT_AFTER}" \
            --arg fingerprint_sha256 "${FINGERPRINT_SHA256}" \
            --arg issued_at "${ISSUED_AT_UTC}" \
            '{domain:$domain, not_after:$not_after, fingerprint_sha256:$fingerprint_sha256, issued_at:$issued_at, source:"letsencrypt-dns-01"}')"

          aws ssm put-parameter \
            --name "${TLS_METADATA_PARAM}" \
            --type String \
            --overwrite \
            --value "${METADATA_JSON}" \
            >/dev/null

          echo "TLS certificate issued for ${TLS_DOMAIN}."
          echo "Certificate metadata written to ${TLS_METADATA_PARAM}."
