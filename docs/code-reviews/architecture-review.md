# Architecture Review: CloudRadar Platform

**Reviewer**: Codex  
**Review Date**: 2026-02-13  
**Scope**: Full platform (Infrastructure + Application + Platform Services)  
**Version**: v1-mvp  

---

## 1. Executive Summary

CloudRadar demonstrates a **well-structured, production-aware cloud architecture** that successfully balances DevOps best practices with portfolio objectives and FinOps constraints. The platform exhibits strong architectural coherence across infrastructure (Terraform/AWS), application (event-driven microservices), and operational concerns (GitOps, observability, security).

**Overall Assessment**: âœ… **STRONG** â€” Production-ready MVP with clear evolution path to v2.

### Key Strengths
1. **Clear architectural vision** with documented decision rationale (19 ADRs)
2. **Strong separation of concerns** (IaC vs GitOps vs application logic)
3. **Cost-aware infrastructure** choices aligned with portfolio context
4. **Security-first mindset** (no SSH, IAM-based access, encrypted state, SSM for secrets)
5. **Observability by design** (Prometheus/Grafana, health/metrics on all services)

### Key Observations
1. Some architectural constraints are MVP-specific and documented for evolution (Redis SPOF, NAT instance, in-memory rate limiter)
2. Event-driven pattern is clean but has a known bottleneck (dashboard HGETALL on large datasets)
3. Architecture documentation is comprehensive and well-maintained
4. Platform demonstrates strong interview readiness (real-world trade-offs, design rationale, operational patterns)

---

## 2. Architecture Overview

### 2.1 Layered Architecture

CloudRadar follows a clean **3-layer architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Infrastructure Layer (Terraform + AWS)                     â”‚
â”‚  VPC Â· EC2 Â· IAM Â· S3 Â· SSM Â· Route53                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Platform Layer (Kubernetes + GitOps)                       â”‚
â”‚  k3s Â· ArgoCD Â· ESO Â· Prometheus Â· Grafana                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Application Layer (Event-Driven Microservices)             â”‚
â”‚  Ingester â†’ Redis â†’ Processor â†’ Dashboard API               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Assessment**: Clean separation with well-defined boundaries. Each layer can evolve independently.

### 2.2 Network Architecture

**Pattern**: Public edge + private compute with NAT instance

```
Internet
   â†“
[Edge EC2 (Nginx)] â† Public Subnet
   â†“ (NodePorts)
[k3s Nodes] â† Private Subnet â†’ [NAT Instance] â†’ Internet
   â†“
[Redis, Apps, Monitoring]
```

**Evaluation**:
- âœ… **Strong**: Clear security boundary (private compute, no SSH, IAM-only access via SSM)
- âœ… **Cost-effective**: NAT instance (~$3-4/month) vs NAT Gateway (~$32/month)
- âš ï¸ **MVP constraint**: NAT instance is SPOF; documented for future HA improvements
- âœ… **Well-documented**: Network diagram with SG flows in `infrastructure.md`

**Security Posture**:
- âœ… Least-privilege security groups (explicit port rules, self-referenced k3s SG)
- âœ… Private subnets for compute (no public IPs on k3s nodes)
- âœ… SSM/KMS VPC endpoints available (currently disabled in dev for cost; HTTPS egress fallback)
- âœ… S3 gateway endpoint for package repos (no NAT traversal for AL2023 updates)

### 2.3 Application Architecture

**Pattern**: Event-driven pipeline with Redis buffer

```
OpenSky API
    â†“
Ingester (Java/Spring) â† OAuth2 tokens from SSM
    â†“ LPUSH
Redis List (cloudradar:ingest:queue)
    â†“ BLPOP
Processor (Java/Spring)
    â†“ HSET/LPUSH/SADD
Redis Aggregates (last positions, tracks, bbox set)
    â†“ HGETALL/LRANGE
Dashboard API (Java/Spring) â† Optional SQLite enrichment
    â†“ GET /api/flights*
Frontend (React/Vite, planned v1.1)
```

**Evaluation**:
- âœ… **Strong**: Clean producer-consumer decoupling via Redis buffer (ADR-0003)
- âœ… **Pragmatic**: Redis chosen over Kafka for MVP simplicity and cost
- âœ… **Type-safe**: All services use Java 17 + Spring Boot for consistency and enterprise alignment (ADR-0014)
- âš ï¸ **Known constraint**: Single-replica Redis is SPOF (ADR-0003 acknowledges this, acceptable for MVP)
- âœ… **Evolution path**: ADR-0003 explicitly preserves Kafka migration path for v2

**Data Flow Robustness**:
- âœ… Ingester has progressive backoff on API failures (exponential, up to 1h before stop)
- âœ… Processor uses blocking BLPOP with timeout (prevents busy-looping, graceful shutdown)
- âš ï¸ Dashboard uses HGETALL on Redis hash (known bottleneck at 10k+ aircraft, documented in dashboard review)

---

## 3. Architectural Patterns & Principles

### 3.1 Infrastructure as Code (Terraform)

**Structure**:
```
infra/aws/
â”œâ”€â”€ bootstrap/         # State backend + shared resources (SQLite backup bucket)
â”œâ”€â”€ live/
â”‚   â”œâ”€â”€ dev/          # Full stack (VPC, NAT, k3s, edge)
â”‚   â””â”€â”€ prod/         # VPC baseline only (app TBD)
â””â”€â”€ modules/
    â”œâ”€â”€ vpc/          # VPC, subnets, route tables, IGW
    â”œâ”€â”€ nat-instance/ # NAT EC2, EIP, route table integration
    â”œâ”€â”€ k3s/          # k3s server + ASG workers, IAM, SG
    â”œâ”€â”€ edge/         # Nginx reverse proxy, SSM auth
    â””â”€â”€ backup-bucket/# SQLite backup bucket (versioned, encrypted)
```

**Assessment**:
- âœ… **Strong module design**: Parameterized, reusable, and composable
- âœ… **Clean root separation**: Bootstrap (state) vs live (environments)
- âœ… **State management**: Remote state in S3 with DynamoDB locking (ADR-0010)
- âœ… **OIDC for CI**: No long-lived AWS credentials in GitHub Actions (ADR-0010)
- âœ… **Destroy-safe**: All resources in modules, clean teardown demonstrated

**CI Integration**:
- âœ… Terraform fmt/validate/plan in CI on PRs
- âœ… Parallel checks across multiple roots (bootstrap, dev, prod)
- âš ï¸ Manual apply only (destructive workflows protected, no auto-merge)

### 3.2 GitOps (ArgoCD)

**Bootstrap Strategy**: SSM Run Command triggered from CI (ADR-0013)

**Rationale**:
- âœ… No kubeconfig exposure (IAM-based, private k3s cluster)
- âœ… Clean separation: Terraform provisions infra, ArgoCD delivers apps
- âœ… Portable to EKS (SSM pattern works for both k3s and EKS)

**ArgoCD Structure**:
```
k8s/
â”œâ”€â”€ platform/          # Shared components (ESO, CRDs)
â”‚   â””â”€â”€ external-secrets/
â”œâ”€â”€ apps/              # Application workloads
    â”œâ”€â”€ ingester/
    â”œâ”€â”€ processor/
    â”œâ”€â”€ dashboard/
    â”œâ”€â”€ monitoring/    # Prometheus + Grafana (Helm Applications)
    â””â”€â”€ redis/
```

**Assessment**:
- âœ… **Strong separation**: Platform (CRDs, operators) vs Apps (workloads)
- âœ… **Sync wave ordering**: ESO CRDs (wave 0) â†’ SecretStore/ExternalSecrets (wave 1)
- âœ… **Declarative drift control**: All apps tracked in Git, ArgoCD auto-sync enabled
- âœ… **Helm via ArgoCD**: Clean integration for EBS CSI, Prometheus, Grafana
- âœ… **Documented conventions**: `k8s/README.md` explains layout and ordering

### 3.3 Event-Driven Architecture

**Pattern**: Queue-based producer-consumer with Redis buffer

**Flow**:
1. **Ingester** fetches OpenSky states â†’ serializes to JSON â†’ LPUSH to Redis list
2. **Processor** BLPOP from list â†’ parses events â†’ updates Redis aggregates (hash, lists, set)
3. **Dashboard API** reads aggregates â†’ enriches with SQLite â†’ serves REST endpoints

**Assessment**:
- âœ… **Decoupling**: Ingester and processor can scale independently
- âœ… **Backpressure handling**: Redis list acts as buffer (bounded by memory, monitored)
- âœ… **Simple semantics**: LPUSH/BLPOP is easy to reason about vs complex message broker
- âš ï¸ **Durability trade-off**: Redis AOF provides persistence, but data loss on pod crash is possible (acceptable for MVP telemetry)
- âœ… **Cost-aware**: Redis in-cluster (no managed service cost) vs MSK/SQS alternatives

**Aggregate Design**:
- âœ… **Last position hash** (`cloudradar:aircraft:last`): O(1) lookup by ICAO24
- âœ… **Track lists** (`cloudradar:aircraft:track:{icao24}`): LTRIM keeps last 180 points
- âœ… **Bbox set** (`cloudradar:aircraft:in_bbox`): Fast membership check for regional queries
- âš ï¸ **Known bottleneck**: Dashboard HGETALL on hash with 10k+ entries (see section 6.3)

### 3.4 Observability-First Design

**Metrics**:
- âœ… All services expose `/metrics` or `/metrics/prometheus`
- âœ… Prometheus auto-discovers via ServiceMonitor labels
- âœ… Standard JVM metrics (ingester, processor, dashboard) + custom business metrics
- âœ… Grafana datasource auto-configured, cluster-local DNS

**Health Checks**:
- âœ… All services expose `/healthz` for liveness probes
- âœ… Dedicated `health` service validates k3s API connectivity for edge health checks

**Logging**:
- âš ï¸ Stdout/stderr only (no aggregation in v1)
- ğŸ“ Planned: Loki integration for v2 (noted in `application-architecture.md`)

**Assessment**:
- âœ… **Strong**: Metrics-first approach (7d retention, 5GB PVC, ~$0.50/month)
- âœ… **Cost-aware**: Prometheus in-cluster vs CloudWatch paid metrics
- âœ… **Production patterns**: Health probes, readiness checks, graceful shutdown
- âš ï¸ **Gap**: Log aggregation deferred to v2 (acceptable for MVP)

### 3.5 Security Architecture

**Principles** (ADR-0009):
1. No plaintext secrets in code or state
2. AWS SSM Parameter Store for runtime secrets
3. Least-privilege IAM roles/policies
4. Encrypted Terraform state (S3 SSE + DynamoDB)

**Implementation**:
- âœ… **No SSH**: IAM-based access via SSM Session Manager
- âœ… **OIDC for CI**: GitHub Actions uses OIDC roles (no static credentials)
- âœ… **Secrets rotation**: SSM parameters for OpenSky OAuth2, Grafana admin, admin-scale HMAC
- âœ… **ESO integration**: External Secrets Operator syncs SSM â†’ K8s Secrets (ADR-0016)
- âœ… **Read-only SQLite**: Aircraft metadata DB opens in `?mode=ro` (integrity, no mutations)
- âœ… **CORS + rate limiting**: Dashboard API has configurable allowlist and per-client quotas

**IAM Posture**:
- âœ… Comprehensive IAM inventory documented (`docs/iam/inventory.md`)
- âœ… Node IAM roles: SSM managed policy + EBS CSI inline policy + S3 backup policy
- âœ… OIDC roles for CI: Terraform plan/apply, Docker build/push

**Assessment**:
- âœ… **Strong**: Security is first-class concern with documented practices
- âœ… **Audit trail**: SSM Session Manager commands logged to CloudTrail
- âœ… **No credential leakage**: `.gitignore` + repo scanning (planned)

---

## 4. Technology Stack Evaluation

### 4.1 Infrastructure Technology Choices

| Technology | Rationale | Assessment |
|-----------|----------|-----------|
| **AWS** | Portfolio target (ADR-0001: us-east-1 for cost + ecosystem) | âœ… Well-suited, cost-optimized choices |
| **Terraform** | Industry-standard IaC, strong AWS provider | âœ… Clean modules, remote state, OIDC |
| **k3s on EC2** | Cost-effective K8s vs EKS (~$75/month savings) (ADR-0002) | âœ… Appropriate for MVP, EKS path preserved |
| **NAT instance** | Cost-effective egress vs NAT Gateway (~$28/month savings) | âœ… Pragmatic MVP choice, HA noted for future |
| **S3 + local-path** | SQLite backups (S3) + k3s default PVC (local-path) | âœ… Cost-effective, migration to EBS planned (#221) |

**Assessment**: Technology choices are **cost-aware and well-justified**. Each decision has a documented ADR with trade-offs and evolution paths.

### 4.2 Application Technology Choices

| Technology | Rationale | Assessment |
|-----------|----------|-----------|
| **Java 17 + Spring Boot** | Enterprise alignment, type-safe, production-proven (ADR-0014) | âœ… Consistent across ingester/processor/dashboard |
| **Redis** | Simple buffer, low-cost, MVP-appropriate (ADR-0003) | âœ… Pragmatic choice, Kafka path preserved |
| **SQLite + S3** | Cost-effective reference data distribution (ADR-0018) | âœ… Innovative pattern, near-zero steady-state cost |
| **Prometheus + Grafana** | Standard observability stack (ADR-0005) | âœ… Production-ready, well-integrated |
| **Python (health/admin)** | Lightweight endpoints, minimal footprint | âœ… Appropriate for auxiliary services |

**Assessment**: Application stack is **enterprise-aligned** with strong consistency (all core services in Java/Spring Boot). Technology choices demonstrate real-world trade-offs.

### 4.3 Platform Technology Choices

| Technology | Rationale | Assessment |
|-----------|----------|-----------|
| **ArgoCD** | GitOps standard, SSM bootstrap (ADR-0013) | âœ… Strong choice, well-executed |
| **External Secrets Operator** | SSM â†’ K8s Secrets sync (ADR-0016) | âœ… Clean integration, sync wave ordering |
| **EBS CSI Driver** | Persistent volumes for stateful workloads | âœ… Deployed via ArgoCD/Helm |
| **Traefik (k3s default)** | In-cluster ingress controller | âœ… Zero-cost, production-ready |

**Assessment**: Platform choices are **production-aware** and follow Kubernetes ecosystem best practices.

---

## 5. Architectural Quality Assessment

### 5.1 Cohesion & Coupling

**Cohesion**: âœ… **Strong**
- Each service has a single, well-defined responsibility
- Clear module boundaries in Terraform (VPC, NAT, k3s, edge)
- Clean namespace separation in k8s (apps, monitoring, data, platform)

**Coupling**: âœ… **Low to Moderate**
- Services communicate via Redis only (no direct service-to-service calls)
- Dashboard API reads Redis aggregates (loose coupling via data contract)
- Ingester and processor are independently scalable
- âš ï¸ **Moderate coupling**: Processor tightly coupled to Redis aggregate schema (acceptable for MVP)

### 5.2 Scalability

**Current Capacity**:
- Ingester: Stateless, can scale horizontally (0-2 replicas via admin-scale API)
- Processor: Single replica (BLPOP blocking consumer, scale-out requires partitioning)
- Dashboard API: Stateless, can scale horizontally
- Redis: Single replica (SPOF, documented MVP constraint)

**Bottlenecks**:
1. âš ï¸ **Redis single replica**: No HA, node affinity on `local-path` PVC
2. âš ï¸ **Dashboard HGETALL**: O(N) memory load for large hashes (10k+ aircraft)
3. âš ï¸ **Processor single consumer**: No horizontal scale-out (requires partitioning strategy)

**Assessment**:
- âœ… Stateless services are horizontally scalable
- âš ï¸ Known bottlenecks documented with evolution plans (Redis HA, processor partitioning, dashboard filter-before-load)

### 5.3 Resilience & Reliability

**Fault Tolerance**:
- âœ… **Ingester**: Progressive backoff on API failures, graceful degradation
- âœ… **Processor**: Blocking BLPOP with timeout, graceful shutdown on signal
- âœ… **Dashboard API**: Best-effort SQLite lookups (returns `Optional.empty()` on failure)
- âš ï¸ **Redis**: No replication, node failure loses buffer + aggregates (acceptable for MVP telemetry)

**Recovery**:
- âœ… Redis AOF persistence enabled (`--appendonly yes`)
- âœ… SQLite backup to S3 (manual snapshots, automation planned)
- âš ï¸ No automatic recovery for Redis data loss (requires manual restore or wait for repopulation)

**Assessment**:
- âœ… Services have graceful degradation patterns
- âš ï¸ Redis SPOF is documented and accepted for MVP
- ğŸ“ Planned: Redis migration to `ebs-gp3` StorageClass for node portability (#221)

### 5.4 Observability

**Metrics Coverage**:
- âœ… Business metrics: ingester events published, processor events consumed, dashboard queries
- âœ… System metrics: JVM heap/threads, Redis ops, HTTP latencies
- âœ… Infrastructure metrics: node-exporter, kube-state-metrics

**Health Checks**:
- âœ… All services expose `/healthz`
- âœ… `health` service validates k3s API connectivity

**Dashboards**:
- âœ… Grafana auto-configured with Prometheus datasource
- âœ… CloudWatch datasource for VPC Flow Logs and AWS-native signals (ADR-0017)
- ğŸ“ Planned: Application-level dashboards (ingester/processor/dashboard panels)

**Assessment**:
- âœ… **Strong**: Observability is first-class concern
- âœ… Metrics exposed on all services, Prometheus scraping configured
- âš ï¸ **Gap**: No centralized logging (deferred to v2)

### 5.5 Security Posture

**Authentication**:
- âœ… Edge: Basic Auth (SSM-stored credentials)
- âœ… OpenSky API: OAuth2 bearer tokens (SSM-stored credentials, 10m cache)
- âœ… Admin-Scale API: HMAC-SHA256 signatures (SSM-stored secret)
- âœ… k3s API: IAM via SSM Session Manager (no kubeconfig exposure)

**Authorization**:
- âœ… IAM roles: Least-privilege policies (node roles, OIDC roles)
- âœ… K8s RBAC: ESO service account, ArgoCD service account
- âœ… Dashboard API: CORS allowlist, rate limiting

**Secrets Management**:
- âœ… No plaintext secrets in code or state
- âœ… SSM Parameter Store for runtime secrets
- âœ… ESO syncs SSM â†’ K8s Secrets (audit trail via CloudTrail)
- âœ… Terraform state encrypted (S3 SSE)

**Network Security**:
- âœ… Private subnets for compute (no public IPs)
- âœ… Security groups with explicit rules (no 0.0.0.0/0 ingress except edge 443)
- âœ… Self-referenced k3s SG for node-to-node traffic

**Assessment**:
- âœ… **Strong**: Security is designed in, not bolted on
- âœ… IAM-first access model (no SSH, no long-lived credentials)
- âœ… Defense in depth (network, IAM, secrets, encryption)

---

## 6. Documentation Quality

### 6.1 Architecture Documentation

**Coverage**:
- âœ… `docs/architecture/infrastructure.md`: Comprehensive infra overview with diagrams
- âœ… `docs/architecture/application-architecture.md`: Detailed service descriptions with code organization
- âœ… 19 ADRs covering all major decisions (network, security, GitOps, tech stack, etc.)
- âœ… Diagrams: Mermaid diagrams for network, data flow, service architecture

**Assessment**:
- âœ… **Excellent**: Architecture is well-documented with rationale and trade-offs
- âœ… Diagrams are clear and up-to-date
- âœ… ADR discipline demonstrates architectural maturity

### 6.2 Operational Documentation

**Runbooks**:
- âœ… `docs/runbooks/README.md`: Entry point with execution order
- âœ… Bootstrap runbooks for AWS, k3s, ArgoCD
- âœ… Observability runbook (Prometheus/Grafana setup)
- âœ… Issue log for troubleshooting (`docs/runbooks/issue-log.md`)

**Assessment**:
- âœ… **Strong**: Runbooks are actionable and well-structured
- âœ… Issue log demonstrates operational learning
- âš ï¸ **Gap**: No failover/DR runbooks (appropriate for MVP)

### 6.3 Code Documentation

**Inline Documentation**:
- âœ… Comprehensive Javadoc on all public classes/methods (ingester, processor, dashboard)
- âœ… Clear comments on complex logic (e.g., backoff algorithm, aggregate updates)
- âœ… Python services have docstrings on key functions

**Assessment**:
- âœ… **Strong**: Code is well-documented for maintainability
- âœ… Documentation standards are consistent across services

---

## 7. Strengths

### 7.1 Strategic Strengths

1. **Clear architectural vision**: Every major decision has a documented ADR with rationale
2. **Cost-aware design**: Technology choices optimize for learning + portfolio showcase, not enterprise budget
3. **Production-ready patterns**: Health checks, metrics, graceful shutdown, progressive backoff
4. **Security-first mindset**: IAM-only access, no SSH, encrypted state, secrets in SSM
5. **Evolution path preserved**: MVP constraints documented with clear v2 migration paths (e.g., Kafka, Redis HA)

### 7.2 Technical Strengths

1. **Clean separation of concerns**: IaC (Terraform) vs GitOps (ArgoCD) vs application logic
2. **Strong module design**: Reusable Terraform modules, composable k8s manifests
3. **Event-driven architecture**: Decoupled services with clear data contracts
4. **Observability by design**: Metrics/health on all services, Prometheus/Grafana auto-configured
5. **Type-safe application stack**: Java 17 + Spring Boot for consistency and enterprise alignment

### 7.3 Portfolio/Interview Strengths

1. **Real-world trade-offs**: NAT instance vs NAT Gateway (cost), k3s vs EKS (cost vs ops burden)
2. **Operational readiness**: Runbooks, issue log, ADRs demonstrate production thinking
3. **CI/CD maturity**: Terraform plan in CI, OIDC for credentials, multi-image builds
4. **GitOps discipline**: All apps tracked in Git, ArgoCD drift control
5. **Comprehensive documentation**: Architecture docs, ADRs, runbooks, code reviews

---

## 8. Weaknesses & Risks

### 8.1 Current Architectural Limitations

#### 8.1.1 Redis Single Point of Failure (High Priority)
- **Issue**: Single-replica Redis, no HA
- **Impact**: Node failure loses buffer + aggregates, requires manual recovery or repopulation
- **Mitigation**: Documented MVP constraint, Redis AOF persistence enabled
- **Remediation**: Migrate to `ebs-gp3` StorageClass + consider Redis Sentinel/Cluster for HA (#221)

#### 8.1.2 Dashboard Memory Bottleneck (Medium Priority)
- **Issue**: `HGETALL` on large hash loads all entries into memory before filtering
- **Impact**: Memory pressure + response time degradation at 10k+ aircraft
- **Mitigation**: Documented in dashboard code review
- **Remediation**: Implement filter-before-load pattern (streaming + early filtering)

#### 8.1.3 Processor Single Consumer (Medium Priority)
- **Issue**: Single BLPOP consumer, no horizontal scale-out
- **Impact**: Throughput ceiling when event rate exceeds single consumer capacity
- **Mitigation**: Current workload (10s interval) does not saturate single consumer
- **Remediation**: Implement partitioning strategy (e.g., hash icao24 to multiple queues)

#### 8.1.4 NAT Instance SPOF (Low Priority, MVP Accepted)
- **Issue**: Single NAT instance, no HA
- **Impact**: Outbound connectivity loss on NAT instance failure
- **Mitigation**: Documented MVP constraint, quick manual recovery via Terraform re-apply
- **Remediation**: Multi-AZ NAT ASG or migrate to NAT Gateway (cost vs reliability trade-off)

### 8.2 Observability Gaps

#### 8.2.1 No Centralized Logging (Low Priority, v2 Planned)
- **Issue**: Logs are stdout/stderr only, no aggregation
- **Impact**: Difficult to correlate logs across services for incident investigation
- **Mitigation**: `kubectl logs` works for MVP debugging
- **Remediation**: Loki integration planned for v2

#### 8.2.2 Limited Alerting (Low Priority, Sprint 2 Planned)
- **Issue**: No AlertManager rules for anomalies (e.g., ingester backoff, processor lag)
- **Impact**: No proactive notification of operational issues
- **Mitigation**: Metrics are exported, can be queried in Grafana
- **Remediation**: Define AlertManager rules for critical thresholds

### 8.3 Testing Gaps

#### 8.3.1 Limited Integration Tests
- **Issue**: No integration tests for Redis interactions, SQLite enrichment, dashboard endpoints
- **Impact**: Regressions may not be caught before deployment
- **Mitigation**: Manual testing + code reviews
- **Remediation**: Add integration tests for critical paths (dashboard service-level tests noted in dashboard review)

#### 8.3.2 No Chaos/Resilience Testing
- **Issue**: No automated testing of failure scenarios (Redis crash, API downtime, network partition)
- **Impact**: Unknown behavior under real-world failure conditions
- **Mitigation**: Services have graceful degradation patterns, documented behavior
- **Remediation**: Add chaos engineering practices for v2 (e.g., Chaos Mesh)

### 8.4 Operational Risks

#### 8.4.1 Manual Secret Rotation
- **Issue**: Secrets (OpenSky OAuth2, Grafana admin) require manual rotation
- **Impact**: Operational burden + risk of stale credentials
- **Mitigation**: Secrets are stored in SSM, rotation process is documented
- **Remediation**: Automate secret rotation via Lambda + SSM Parameter Store lifecycle hooks

#### 8.4.2 No Disaster Recovery Plan
- **Issue**: No documented DR/failover runbook
- **Impact**: Extended downtime in catastrophic failure (e.g., AWS region outage)
- **Mitigation**: Terraform can rebuild infra from scratch, ArgoCD re-syncs apps
- **Remediation**: Document DR runbook with RTO/RPO targets

---

## 9. Recommendations

### 9.1 High Priority (Pre-Production)

#### 9.1.1 Redis Resilience (#221)
**Action**: Migrate Redis PVC from `local-path` to `ebs-gp3` StorageClass  
**Rationale**: Removes node affinity lock-in, enables pod rescheduling on node failure  
**Effort**: Low (change StorageClass in manifest, re-provision)  
**Impact**: High (improves Redis reliability)

#### 9.1.2 Dashboard Filter-Before-Load Optimization
**Action**: Refactor `FlightQueryService.loadSnapshots()` to filter during load, not after  
**Rationale**: Reduces memory footprint and improves response times at scale  
**Effort**: Medium (refactor data access pattern)  
**Impact**: High (enables dashboard to handle 10k+ aircraft)

#### 9.1.3 Integration Tests for Dashboard API
**Action**: Add service-level tests for `FlightQueryService` (see dashboard review)  
**Rationale**: De-risk regressions during future changes  
**Effort**: Medium (add test fixtures + assertions)  
**Impact**: Medium (improves change confidence)

### 9.2 Medium Priority (v1.1)

#### 9.2.1 Redis HA (Sentinel or Cluster)
**Action**: Evaluate Redis Sentinel vs Redis Cluster for HA  
**Rationale**: Removes Redis SPOF, enables automatic failover  
**Effort**: High (operational complexity increase)  
**Impact**: High (production readiness)

#### 9.2.2 Processor Horizontal Scaling
**Action**: Implement partitioning strategy (e.g., hash icao24 to multiple queues)  
**Rationale**: Enables horizontal scale-out for higher event rates  
**Effort**: High (requires queue partitioning + consumer coordination)  
**Impact**: Medium (future-proofs for higher workloads)

#### 9.2.3 Centralized Logging (Loki)
**Action**: Deploy Loki + Promtail for log aggregation  
**Rationale**: Improves incident investigation and correlation  
**Effort**: Medium (deploy via ArgoCD, configure log scraping)  
**Impact**: Medium (operational visibility)

### 9.3 Low Priority (v2 / Future)

#### 9.3.1 Multi-AZ Deployment
**Action**: Deploy k3s nodes across multiple AZs with multi-AZ Redis  
**Rationale**: Improves availability against AZ failures  
**Effort**: High (network design, data replication)  
**Impact**: High (enterprise-grade availability)

#### 9.3.2 Migrate to EKS
**Action**: Evaluate EKS migration when AWS cost budget increases  
**Rationale**: Reduces operational burden (managed control plane, auto-upgrades)  
**Effort**: Medium (Terraform modules already portable, ADR-0013 designed for EKS)  
**Impact**: Medium (reduced ops burden, higher cost)

#### 9.3.3 Automated Secret Rotation
**Action**: Implement Lambda + SSM lifecycle hooks for secret rotation  
**Rationale**: Reduces operational burden and security risk  
**Effort**: Medium (Lambda function + SSM integration)  
**Impact**: Low (improves security hygiene)

#### 9.3.4 Chaos Engineering
**Action**: Introduce Chaos Mesh for automated resilience testing  
**Rationale**: Validates failure handling in realistic scenarios  
**Effort**: Medium (deploy Chaos Mesh, define experiments)  
**Impact**: Medium (confidence in production behavior)

---

## 10. Comparative Analysis (vs Industry Standards)

### 10.1 vs Enterprise Production Systems

| Aspect | CloudRadar | Enterprise Standard | Gap Assessment |
|--------|-----------|---------------------|----------------|
| **IaC Coverage** | 100% (Terraform) | 100% (Terraform/Pulumi/CDK) | âœ… At parity |
| **GitOps** | ArgoCD | ArgoCD/Flux | âœ… At parity |
| **Observability** | Prometheus + Grafana | Prometheus + Grafana (or DataDog) | âœ… At parity |
| **CI/CD** | GitHub Actions | Jenkins/GitLab/GitHub Actions | âœ… At parity |
| **Secrets Management** | SSM + ESO | Vault/SSM/Secrets Manager | âš ï¸ Good (no rotation automation) |
| **High Availability** | Single-replica Redis | Multi-AZ Redis Cluster | âš ï¸ MVP constraint |
| **Disaster Recovery** | Manual rebuild | Automated DR runbooks | âš ï¸ No DR plan |
| **Logging** | stdout/stderr | ELK/Loki/Splunk | âš ï¸ v2 planned |
| **Alerting** | None | AlertManager/PagerDuty | âš ï¸ Sprint 2 planned |

**Assessment**: CloudRadar demonstrates **production-aware architecture** with explicit MVP constraints. Gaps are documented and prioritized.

### 10.2 vs Portfolio/Demo Projects

| Aspect | CloudRadar | Typical Portfolio Project | CloudRadar Advantage |
|--------|-----------|--------------------------|----------------------|
| **Architecture Documentation** | 19 ADRs + diagrams | Minimal or missing | âœ… Strong |
| **Operational Runbooks** | Comprehensive | Rare | âœ… Strong |
| **Cost Awareness** | Explicit FinOps trade-offs | Often ignored | âœ… Strong |
| **Production Patterns** | Health checks, metrics, graceful shutdown | Often missing | âœ… Strong |
| **Security** | IAM-only, no SSH, SSM secrets | Often hardcoded | âœ… Strong |
| **CI/CD** | Terraform plan in CI, OIDC | Basic or manual | âœ… Strong |
| **GitOps** | ArgoCD + sync waves | Manual kubectl | âœ… Strong |

**Assessment**: CloudRadar is **significantly above** typical portfolio projects in architecture maturity and operational readiness.

---

## 11. Architecture Maturity Assessment

Using the **Architecture Maturity Model** (5 levels):

| Dimension | Level | Evidence |
|-----------|-------|----------|
| **Documentation** | 4/5 (Managed) | ADRs, architecture docs, runbooks, diagrams |
| **Automation** | 4/5 (Managed) | Terraform, GitOps, CI/CD, ESO |
| **Observability** | 3/5 (Defined) | Metrics + health, no logging aggregation |
| **Resilience** | 3/5 (Defined) | Graceful degradation, documented SPOFs |
| **Security** | 4/5 (Managed) | IAM-first, encrypted state, SSM secrets, OIDC |
| **Testing** | 2/5 (Repeatable) | Unit tests exist, integration tests limited |
| **Operational Excellence** | 3/5 (Defined) | Runbooks present, no alerting/DR |

**Overall Maturity**: **3.4/5 (Defined â†’ Managed)**

**Interpretation**: CloudRadar demonstrates **strong architectural discipline** with well-documented practices. It sits between "Defined" (documented processes) and "Managed" (measured and controlled). For a portfolio MVP, this is **excellent**.

---

## 12. Interview Readiness Assessment

### 12.1 Demonstrated Skills

| Skill Area | Evidence | Strength |
|-----------|----------|----------|
| **Cloud Architecture** | AWS VPC design, cost-aware choices, security boundaries | âœ… Strong |
| **Infrastructure as Code** | Terraform modules, remote state, OIDC | âœ… Strong |
| **GitOps** | ArgoCD bootstrap via SSM, sync waves, drift control | âœ… Strong |
| **Kubernetes** | k3s on EC2, Helm integration, RBAC, PVCs | âœ… Strong |
| **Event-Driven Systems** | Redis buffer, producer-consumer, aggregates | âœ… Strong |
| **Observability** | Prometheus, Grafana, custom metrics, health checks | âœ… Strong |
| **Security** | IAM, SSM, ESO, OIDC, encrypted state | âœ… Strong |
| **FinOps** | Cost trade-offs (NAT instance, k3s, Redis in-cluster) | âœ… Strong |
| **Documentation** | ADRs, architecture docs, runbooks, diagrams | âœ… Excellent |
| **Operational Excellence** | Runbooks, issue log, code reviews | âœ… Strong |

### 12.2 Interview Talking Points

**Strong narratives**:
1. **Cost-aware architecture**: "We chose k3s over EKS to save ~$75/month while preserving a production-like Kubernetes experience. The trade-off is operational burden, which is acceptable for a portfolio project. ADR-0002 documents this decision and preserves the EKS migration path."

2. **Security-first design**: "We use IAM-only access with no SSH. All secrets are in SSM, synced to Kubernetes via External Secrets Operator. CI uses OIDC roles, not long-lived credentials. This demonstrates enterprise security practices without complex tooling."

3. **Event-driven resilience**: "The ingester has progressive backoff on API failures, starting at 1 second and eventually backing off to 1 hour before stopping. This prevents API abuse and demonstrates graceful degradation. The backoff levels are exposed as Prometheus metrics for observability."

4. **GitOps at scale**: "ArgoCD is bootstrapped via SSM Run Command from CI, which allows us to deploy to a private k3s cluster without exposing kubeconfig. This pattern is portable to EKS and demonstrates IAM-first access. ADR-0013 compares 5 bootstrap strategies."

5. **Production trade-offs**: "Redis is single-replica for MVP, which is a known SPOF. We document this in ADR-0003 and accept the risk for telemetry data. The migration path to Redis Sentinel is preserved. This demonstrates real-world cost vs reliability trade-offs."

### 12.3 Red Flags (None Identified)

**Anti-patterns NOT present**:
- âŒ Hardcoded secrets
- âŒ Manual kubectl in production
- âŒ Undocumented architectural decisions
- âŒ No observability
- âŒ No CI/CD
- âŒ Cost-blind infrastructure choices

**Assessment**: âœ… **Interview-ready**. The architecture demonstrates strong DevOps/Cloud practices with clear rationale for trade-offs.

---

## 13. Final Verdict

### 13.1 Overall Architecture Rating: **4.2/5 (Strong)**

**Breakdown**:
- **Design**: 4.5/5 (clean separation, event-driven, well-documented)
- **Implementation**: 4.0/5 (production patterns, known constraints documented)
- **Documentation**: 4.5/5 (ADRs, runbooks, diagrams)
- **Operational Readiness**: 3.5/5 (metrics + health, gaps in logging/alerting)
- **Security**: 4.5/5 (IAM-first, encrypted state, SSM secrets)

### 13.2 Production Readiness: **âœ… MVP-Ready with Documented Constraints**

CloudRadar is **production-ready for MVP deployment** with the following caveats:
- âœ… All services have health checks and metrics
- âœ… Infrastructure is reproducible via Terraform
- âœ… GitOps provides drift control
- âš ï¸ Redis SPOF is accepted MVP constraint (documented)
- âš ï¸ No centralized logging (acceptable for MVP)
- âš ï¸ No alerting rules (acceptable for MVP)

### 13.3 Portfolio/Interview Readiness: **âœ… Excellent**

CloudRadar is **significantly above typical portfolio projects** in:
- Architecture documentation (19 ADRs)
- Operational readiness (runbooks, issue log)
- Production patterns (health/metrics, graceful degradation)
- Security discipline (IAM-first, no SSH, encrypted state)
- Cost awareness (explicit FinOps trade-offs)

**Interview confidence**: High. The architecture demonstrates **real-world DevOps/Cloud experience** with strong rationale for design decisions.

---

## 14. Conclusion

CloudRadar exhibits a **well-designed, production-aware architecture** that successfully balances DevOps best practices with portfolio objectives and cost constraints. The platform demonstrates:

1. **Strong architectural coherence** across infrastructure, platform, and application layers
2. **Clear separation of concerns** (IaC vs GitOps vs application logic)
3. **Production patterns** (health checks, metrics, graceful shutdown, progressive backoff)
4. **Security-first mindset** (IAM-only, encrypted state, SSM secrets, OIDC)
5. **Comprehensive documentation** (19 ADRs, architecture docs, runbooks, diagrams)

**Key architectural strengths**:
- Event-driven design with clean producer-consumer decoupling
- GitOps-first deployment with ArgoCD sync waves
- Cost-aware infrastructure choices with documented trade-offs
- Observability by design (metrics on all services, Prometheus/Grafana)

**Known constraints**:
- Redis SPOF (accepted MVP constraint, migration path documented)
- Dashboard memory bottleneck (documented, remediation identified)
- No centralized logging (v2 planned)
- No alerting rules (Sprint 2 planned)

**Overall assessment**: CloudRadar is a **strong portfolio project** that demonstrates production-ready DevOps/Cloud architecture with clear evolution paths. The architecture is **interview-ready** with compelling narratives around cost-aware design, security practices, and operational maturity.

---

**Reviewed by**: Codex  
**Review Date**: 2026-02-13  
**Recommendation**: âœ… **Proceed with v1-mvp deployment** â€” Architecture is solid with documented constraints
