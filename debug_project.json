{"items":[{"assignees":["ClementV78"],"content":{"body":"## Goal\nProvision a minimal, cost-aware k3s cluster for the MVP using Terraform only. The cluster must be fully reproducible/destroyable, use private subnets, and rely on SSM for access (no public SSH).\n\n## Scope\n### Compute\n- k3s server: single `aws_instance` in private subnet (t3.small, gp3 ~~20GB~~ 40GB root, IMDSv2 enforced)\n- k3s workers: `aws_launch_template` + `aws_autoscaling_group` (t3.micro, gp3 ~~20GB~~ 40GB root, IMDSv2 enforced)\n  - min = 1, desired = var.worker_desired, max = 3\n- NAT instance: single EC2 in public subnet (t3.nano or t3.micro), egress only, source/dest check disabled (Amazon Linux 2 AMI)\n\n### IAM / Access\n- `aws_iam_role` + `aws_iam_instance_profile` for EC2\n- Attach `AmazonSSMManagedInstanceCore` only\n\n### Network\n- Private subnets for all k3s nodes (no public IPs)\n- Security group rules must be explicit for k3s ports (no permissive intra-SG rule)\n- NAT instance provides outbound Internet for cloud-init and image pulls\n\n### Bootstrap\n- `random_password` generates the k3s join token\n- `cloud-init` with `data \"cloudinit_config\"` for server and workers\n- Workers join using the server private IP injected into the launch template\n- k3s server runs with `--secrets-encryption`\n\n### VPC Dependencies\n- Consume outputs from VPC module: `vpc_id`, `private_subnet_ids`, `public_subnet_ids` (for NAT)\n\n## Out of scope\n- CloudWatch logs/alarms (observability is Prometheus/Grafana only)\n- SSM Parameter Store for token\n- NAT Gateway\n- Cluster Autoscaler / Karpenter\n- CPU-based ASG scaling policies\n\n## DoD\n- k3s module added under `infra/modules/` with no ad-hoc EC2 in env roots\n- k3s server + workers provisioned via Terraform using private subnets only\n- NAT instance enabled to allow cloud-init outbound access\n- IMDSv2 enforced and root volumes set to gp3 with explicit sizes\n- Security group rules are explicit for required k3s ports\n- Token generation and join flow handled via Terraform (no manual steps)\n- CI checks green\n- Docs/README/ADR updated if needed\n- Plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #1 (VPC)\n","number":7,"repository":"ClementV78/CloudRadar","title":"feat(infra): provision EC2 k3s nodes (server + agent) with cloud-init (secrets encryption)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/7"},"id":"PVTI_lAHOCf--fM4BKOL_zgixczM","labels":["area/infra","area/k8s","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/89"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"L","sprint":{"duration":14,"iterationId":"9b37ee5b","startDate":"2026-01-01","title":"Sprint 2"},"status":"Done","title":"feat(infra): provision EC2 k3s nodes (server + agent) with cloud-init (secrets encryption)"},{"assignees":["ClementV78"],"content":{"body":"v1 MVP: public Edge EC2 running Nginx. TLS termination (auto-signed), Basic Auth, reverse proxy to k3s services (NodePort) in private subnet.\n\n## Scope\n### Edge EC2\n- Public subnet instance (t3.micro default)\n- IMDSv2 enforced, gp3 root volume\n- Access via SSM only (no SSH)\n\n### TLS + Basic Auth\n- Self-signed cert generated at boot\n- Basic Auth enabled (htpasswd)\n- Password pulled from SSM Parameter Store at boot\n- TODO: migrate to ACM + Route53 (issue #14)\n\n### Reverse proxy\n- Nginx proxies to k3s NodePort services\n- Dashboard + API ports configured via variables\n\n### Network\n- SG allows 443 (and 80 for redirect) from `edge_allowed_cidrs`\n- Egress restricted to private subnet CIDRs\n\n### Inputs (dev)\n- `edge_allowed_cidrs` (start with admin IP, can switch to 0.0.0.0/0)\n- `edge_basic_auth_ssm_parameter_name` (SSM param with password)\n- `edge_dashboard_nodeport`, `edge_api_nodeport`\n\n### VPC Dependencies\n- Uses VPC outputs + k3s server private IP for upstream host\n\n## üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #1 (VPC).\n","number":8,"repository":"ClementV78/CloudRadar","title":"feat(edge): deploy Nginx on EC2 (public HTTPS + Basic Auth) reverse proxy to Dashboard/API","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/8"},"id":"PVTI_lAHOCf--fM4BKOL_zgixc5w","labels":["area/infra","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/93","https://github.com/ClementV78/CloudRadar/pull/108"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"9b37ee5b","startDate":"2026-01-01","title":"Sprint 2"},"status":"Done","title":"feat(edge): deploy Nginx on EC2 (public HTTPS + Basic Auth) reverse proxy to Dashboard/API"},{"assignees":["ClementV78"],"content":{"body":"### üéØ Objective\nConfigure Terraform to **use** the remote backend (S3 + DynamoDB) created by the bootstrap workflow.\n\n### ‚öôÔ∏è Specifications\n1) **Backend Config (S3/DynamoDB)**\n- Use the bucket and table created by #33\n- Enable versioning + encryption + block public access (already set by bootstrap)\n- Keep config reusable across envs (e.g., backend config file or variables)\n\n2) **OIDC GitHub Actions**\n- Ensure Terraform workflows can assume the CI role via OIDC (role created in #32)\n- No static AWS keys stored\n\n### ‚úÖ Tasks\n- Add backend config for `infra/live/*` to use S3 + DynamoDB\n- Update or add CI workflow steps to use OIDC credentials (where relevant)\n- Document how to initialize Terraform with the remote backend\n\n### üîó Dependencies\n- Depends on #33 (bootstrap S3/DynamoDB via CI).\n\n### üèÅ DoD\n- `terraform init` uses S3 remote state\n- DynamoDB lock is active on plan/apply\n- GitHub Actions can assume the role via OIDC","number":6,"repository":"ClementV78/CloudRadar","title":"feat(infra): bootstrap Terraform Remote Backend & OIDC Security","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/6"},"id":"PVTI_lAHOCf--fM4BKOL_zgiaYyE","labels":["area/infra","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/37"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"9b37ee5b","startDate":"2026-01-01","title":"Sprint 2"},"status":"Done","title":"feat(infra): bootstrap Terraform Remote Backend & OIDC Security"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nEnsure ArgoCD bootstrap runs only after k3s readiness check succeeds.\n\n## Context\nRecent runs show argocd-bootstrap can fail when the API server is not yet ready. The k3s-ready-check already validates readiness with retries.\n\n## Scope\n- Make `argocd-bootstrap` depend on `k3s-ready-check` (and `tf-outputs`).\n- Keep current smoke tests behavior.\n- Update workflow diagram/runbook if needed.\n- Remove duplicate `Namespace` manifests under `k8s/apps` to avoid kustomize `ComparisonError` in ArgoCD.\n\n## DoD\n- `argocd-bootstrap` starts only after `k3s-ready-check` success.\n- CI workflow graph reflects the new dependency.\n- Docs updated if behavior changes.\n- `kustomize build k8s/apps` does not fail on duplicate Namespace.\n\n## Notes\n- Keep changes minimal and scoped to ci-infra workflow and k8s/apps namespace hygiene.","number":143,"repository":"ClementV78/CloudRadar","title":"ci(infra): run argocd bootstrap after k3s ready","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/143"},"id":"PVTI_lAHOCf--fM4BKOL_zgkL19Y","labels":["area/infra","v1-mvp","kind/ci"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/144"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"ci(infra): run argocd bootstrap after k3s ready"},{"assignees":["ClementV78"],"content":{"body":"### üéØ Objective\nProvision a cost-optimized AWS network for the v1 architecture: **public Edge** + **private k3s** (no EKS). Includes the VPC, subnets, and routing **to** a NAT instance (the NAT instance itself is delivered in #7).\n\n### ‚öôÔ∏è Specifications (v1)\n- **Region:** `<region>` (see #31)\n- **CIDR:** per environment, see ADR-0008: https://github.com/ClementV78/CloudRadar/blob/main/docs/architecture/decisions/ADR-0008-2026-01-08-vpc-public-edge-private-k3s-nat-instance.md\n- **Architecture (per env: dev, prod):**\n  - 1 VPC per environment (no shared VPC between envs)\n  - 1 Internet Gateway (IGW)\n  - **1 Public Subnet** (Edge Nginx EC2)\n  - **1 Private Subnet** (k3s nodes EC2)\n  - **Route to NAT Instance** so private nodes can reach the internet (updates, image pulls) without NAT Gateway. **NAT instance is implemented in #7.**\n- **Tags:** `Project=CloudRadar`, `Env=<env>`\n\n### üß© Terraform modules (scope)\n- VPC implemented as a reusable module under `infra/aws/modules/vpc`\n- Environment roots under `infra/aws/live/<env>` consume module outputs (no duplicated networking resources)\n\n### ‚úÖ Tasks\n- [ ] Initialize `infra/aws/modules/vpc`\n- [ ] VPC + IGW\n- [ ] Public subnet + route table `0.0.0.0/0 -> IGW`\n- [ ] Private subnet + route table `0.0.0.0/0 -> NAT Instance` (route only; NAT instance in #7)\n- [ ] SG ‚ÄúEdge‚Äù (443 public) + SG ‚ÄúNodes‚Äù (traffic from Edge + intra-nodes)\n- [ ] Outputs: `vpc_id`, `public_subnet_id`, `private_subnet_id`, `edge_sg_id`, `nodes_sg_id`\n\n### üèÅ DoD\n- `terraform fmt` / `validate` OK\n- `terraform plan` in `infra/aws/live/dev` shows the expected topology (VPC/IGW/subnets/routes); NAT instance created in #7\n\n## Dependencies\n- Depends on #31 (region decision).\n- NAT instance delivery tracked in #7.\n","number":1,"repository":"ClementV78/CloudRadar","title":"feat(infra): provision VPC (public Edge + private k3s, NAT instance)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/1"},"id":"PVTI_lAHOCf--fM4BKOL_zgiaDLo","labels":["area/infra","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/49"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"L","sprint":{"duration":14,"iterationId":"9b37ee5b","startDate":"2026-01-01","title":"Sprint 2"},"status":"Done","title":"feat(infra): provision VPC (public Edge + private k3s, NAT instance)"},{"assignees":["ClementV78"],"content":{"body":"üé´ Ticket #2: EKS Cluster Foundation (Updated)\nTitle: feat(infra): provision EKS 1.34 Cluster with Terraform Labels: area/infra, sprint-0 Status: Todo\n\nüéØ Objective\nDeploy a production-grade Kubernetes Cluster (EKS) connected to the VPC. Constraint: All resources must be provisioned via Terraform. No manual actions in AWS Console.\n\n‚öôÔ∏è Technical Specifications\n1. Control Plane\n\nVersion: 1.34 (Matches latest AWS support).\nNetwork: Private Subnets (from Ticket #1).\nSecurity:\nEnable OIDC Provider (Mandatory for IRSA).\nEndpoint: Public/Private (Restricted CIDR if possible).\nAdd-ons (managed via Terraform):\nvpc-cni\ncoredns\nkube-proxy\naws-ebs-csi-driver (Required for Kafka persistence).\n\n2. Data Plane (Managed Node Group)\n\nInstance: t3.medium.\nScaling: ASG (Auto Scaling Group) defined in code (Min: 1, Max: 3).\nDisk: gp3 (EBS).\n\n‚úÖ Implementation Tasks (IaC)\n[ ] Create infra/modules/eks module using terraform-aws-modules/eks/aws or custom resources.\n[ ] Define IAM Roles (Cluster & Node) in Terraform iam.tf.\n[ ] Instantiate the cluster in infra/live/dev/main.tf passing the vpc_id and subnet_ids from module #1.\n[ ] Output kubeconfig update command via Terraform local_file or output.\n\nüèÅ Definition of Done\nterraform plan shows the creation of the EKS Control Plane + Node Group.\n\nRunning aws eks update-kubeconfig allows connection to the cluster.\n\nkubectl get nodes returns version v1.34.x.","number":2,"repository":"ClementV78/CloudRadar","title":"feat(v2): EKS cluster foundation with Terraform [postponed]","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/2"},"id":"PVTI_lAHOCf--fM4BKOL_zgiaDFk","labels":["duplicate","area/infra"],"milestone":{"description":"","dueOn":"","title":"v2"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"feat(v2): EKS cluster foundation with Terraform [postponed]"},{"assignees":["ClementV78"],"content":{"body":"üéØ Objective\nImplement the Event-Driven backbone using Strimzi. Constraint: Everything must be defined as Kubernetes Manifests (YAML) in the k8s/ folder. \n\n‚öôÔ∏è Technical Specifications\n1. Operator (Platform Layer)\n\nSource: Strimzi Helm Chart or YAML Bundle.\nMethod: Use kustomize to manage the installation.\nLocation: k8s/platform/strimzi/.\n\n2. Kafka Cluster (Application Layer)\n\nResource: Kafka (CRD).\nConfig:\n- Replicas: 1 (Dev).\n- Storage: ephemeral (for Sprint 0 cost saving).\n- Listeners: plain (port 9092, internal).\n- Location: k8s/apps/kafka-cluster/overlays/dev/.\n\n‚úÖ Implementation Tasks (IaC)\n[ ] Create k8s/platform/strimzi/kustomization.yaml referencing the upstream Strimzi install files.\n[ ] Create k8s/apps/kafka-cluster/base/kafka.yaml (The Cluster CRD).\n[ ] Create k8s/apps/kafka-cluster/base/topic.yaml (The \"flight-telemetry\" Topic CRD).\n[ ] Create k8s/apps/kafka-cluster/overlays/dev/kustomization.yaml to patch specific dev configurations.\n\nüèÅ Definition of Done\nNo manual helm install commands.\nRunning kubectl apply -k k8s/platform/strimzi installs the operator.\nRunning kubectl apply -k k8s/apps/kafka-cluster/overlays/dev spins up the broker.\n\n## Dependencies\n- Depends on #26 or #7 (Kubernetes cluster available).\n","number":3,"repository":"ClementV78/CloudRadar","title":"feat(v2): Kafka via Strimzi (operator + cluster) [postponed]","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/3"},"id":"PVTI_lAHOCf--fM4BKOL_zgiaR9M","labels":["duplicate","area/k8s"],"milestone":{"description":"","dueOn":"","title":"v2"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"feat(v2): Kafka via Strimzi (operator + cluster) [postponed]"},{"assignees":["ClementV78"],"content":{"body":"üéØ Objective\nAutomate the validation of our Infrastructure as Code. Constraint: The CI must act as a quality gate for the infra/ folder.\n\n‚öôÔ∏è Technical Specifications\nWorkflow: GitHub Actions (.github/workflows/ci-infra.yml).\nTools: terraform, tflint (optional).\n\n‚úÖ Implementation Tasks (IaC Automation)\n[ ] Define workflow trigger: on: [pull_request] for paths infra/**.\n[ ] Step 1: hashicorp/setup-terraform.\n[ ] Step 2: terraform fmt -check (Enforce style).\n[ ] Step 3: terraform validate (Enforce syntax).\n[ ] Step 4: terraform plan (Speculative plan to check for errors against AWS API).\n\nüß© Terraform modules (scope)\n- CI must validate both:\n  - module code under `infra/modules/**`\n  - environment roots under `infra/live/**` (composition of modules)\n- Add tfsec as a security gate (in addition to fmt/validate/plan)\n\nüèÅ Definition of Done\nA PR modifying infra/ triggers the action.\nThe action turns üî¥ if formatting is bad.\nThe action turns üü¢ if terraform plan succeeds.\n\n## Dependencies\n- Depends on #32 (AWS account + OIDC).\n- Depends on #6 (remote backend config).\n","number":4,"repository":"ClementV78/CloudRadar","title":"ci(infra): setup Terraform Validation Workflow","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/4"},"id":"PVTI_lAHOCf--fM4BKOL_zgiaSRc","labels":["kind/maintenance","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/42"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"S","sprint":{"duration":14,"iterationId":"9b37ee5b","startDate":"2026-01-01","title":"Sprint 2"},"status":"Done","title":"ci(infra): setup Terraform Validation Workflow"},{"assignees":["ClementV78"],"content":{"body":"### Goal\nInitialize and extend the **Processor** microservice (Spring Boot) to aggregate OpenSky positions for the v1 radar UI.\n\n### Specs (v1)\n- **Input:** consume events from **Redis** (queue/buffer) fed by the OpenSky ingester (#111)\n- **Storage (v1):** write aggregates to **Redis** (in-memory) for fast UI access\n- **Outputs (v1):**\n  - **Last position per aircraft** (keyed by `icao24`)\n  - **Short track** (N last positions per aircraft)\n  - **Global counter** of aircraft inside the default bbox\n- **Observability:** expose `/metrics` for Prometheus\n- **K8s:** Deployment + Service, probes, resources\n\n### Tasks\n- [ ] Init Spring Boot project `src/processor`\n- [ ] Container build (Dockerfile or Jib)\n- [ ] Manifests `k8s/apps/processor/base` (deployment + service)\n- [ ] Add readiness/liveness probes\n- [ ] Add requests/limits\n- [ ] Expose `/metrics` and ensure Prometheus can scrape it\n- [ ] Implement last-position store (per `icao24`)\n- [ ] Implement short-track store (N last points per `icao24`)\n- [ ] Implement global bbox counter (aircraft currently inside bbox)\n\n### DoD\n- Build OK (image)\n- Deploy OK on k3s\n- Processor consumes Redis and writes aggregates to Redis in dev\n- `/metrics` reachable via curl (Prometheus validation optional until #10)\n- Last-position + short-track + bbox counter data available for API/UI consumers\n\n### Validation Steps\n- Confirm `/metrics` responds via a manual HTTP check.\n- Validate last-position / track / counter via Redis queries or logs.\n- If #10 is available, confirm Prometheus scraping is active.\n\n### Dependencies\n- Depends on #7 (k3s cluster).\n- Depends on #9 (Redis).\n- Depends on #111 (OpenSky ingester).\n- Optional: #10 (Prometheus/Grafana) for /metrics validation (manual curl accepted before #10).\n\n### References\n- ADR: https://github.com/ClementV78/CloudRadar/blob/main/docs/architecture/decisions/ADR-0014-2026-01-19-processor-language-java.md\n\n## Out of scope\n- Persisting aggregates to SQLite (tracked in #165).\n- Zone-based alerting (tracked in #128).\n- Dashboard API endpoints are tracked in #129.\n","number":5,"repository":"ClementV78/CloudRadar","title":"feat(app): init Processor Service & K8s Manifests","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/5"},"id":"PVTI_lAHOCf--fM4BKOL_zgiaVYs","labels":["area/app","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/166"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"In progress","title":"feat(app): init Processor Service & K8s Manifests"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nUse the same `terraform.tfvars` file in both local runs and GitHub Actions, while keeping sensitive values out of git.\n\n## Context\nToday CI uses `terraform.tfvars.example` while local uses `terraform.tfvars`, which can drift. We want a single non-sensitive tfvars committed, and inject secrets via `TF_VAR_*` in CI and a local .env (not committed).\n\n## Scope\n- Commit a sanitized `infra/aws/live/dev/terraform.tfvars` (non-sensitive only).\n- Ensure sensitive values are provided via environment variables (TF_VAR_*).\n- Update `ci-infra` workflow to load `terraform.tfvars` (not `.example`) and rely on secrets/vars for sensitive inputs.\n- Add `.env` (or `.envrc`) pattern to `.gitignore`.\n- Document local workflow (how to load .env) and CI expectations in runbooks/README.\n- Keep `terraform.tfvars.example` only if still useful (decide and document).\n\n## DoD\n- CI and local both use the same `terraform.tfvars` file.\n- Sensitive values are injected via TF_VAR_* in CI and local .env.\n- Docs updated to explain the workflow and list required secrets/vars.\n- `.gitignore` updated to ignore local env files.\n\n## Notes\n- No plaintext secrets committed.\n- Ensure `terraform.tfvars` in git contains only non-sensitive values.","number":141,"repository":"ClementV78/CloudRadar","title":"ci(infra): align tfvars usage between local and CI","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/141"},"id":"PVTI_lAHOCf--fM4BKOL_zgkLsos","labels":["area/infra","v1-mvp","kind/ci"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/157"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"ci(infra): align tfvars usage between local and CI"},{"assignees":["ClementV78"],"content":{"body":"Align README with v1 (k3s on EC2, Redis, SQLite, Nginx edge, Prom/Grafana, S3 backups) and add diagram under docs/architecture/.","number":12,"repository":"ClementV78/CloudRadar","title":"docs(readme): update README + add v1 high-level architecture diagram","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/12"},"id":"PVTI_lAHOCf--fM4BKOL_zgixcqQ","labels":["area/docs"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","sprint":{"duration":14,"iterationId":"4feec353","startDate":"2025-12-18","title":"Sprint 1"},"status":"Done","title":"docs(readme): update README + add v1 high-level architecture diagram"},{"assignees":["ClementV78"],"content":{"body":"## Context\nADR-0013 defines the GitOps bootstrap strategy for ArgoCD via SSM.\nAfter a `terraform destroy`, ArgoCD must be reinstalled automatically during `ci-infra` apply.\n\n## Scope\n- Run `scripts/bootstrap-argocd.sh` via SSM after successful `terraform apply` in `ci-infra`.\n- Use Terraform outputs for the k3s/ArgoCD instance ID and region.\n- Keep the cluster private (no kubeconfig exposure; no SSH).\n- Ensure the step is rerunnable/idempotent.\n\n## DoD\n- `ci-infra` installs ArgoCD via SSM after apply and logs the result.\n- ArgoCD syncs the root app and deploys `healthz` from `k8s/apps`.\n- No SSH usage; access remains IAM/SSM-only.\n- Docs updated if workflow behavior changes.\n\n## Links\n- ADR: docs/architecture/decisions/ADR-0013-2026-01-17-gitops-bootstrap-strategy-argocd.md","number":104,"repository":"ClementV78/CloudRadar","title":"feat(infra): automate ArgoCD bootstrap in ci-infra","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/104"},"id":"PVTI_lAHOCf--fM4BKOL_zgj06VE","labels":["enhancement","area/infra","v1-mvp","kind/ci"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/105"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"feat(infra): automate ArgoCD bootstrap in ci-infra"},{"assignees":["ClementV78"],"content":{"body":"v1 MVP: deploy redis:7-alpine (Deployment + ClusterIP Service) in data ns. Add resources, basic config, and connect Ingester/Processor.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #7 (k3s cluster).\n","number":9,"repository":"ClementV78/CloudRadar","title":"feat(k8s): deploy Redis in data namespace (queue/buffer) + wiring for apps","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/9"},"id":"PVTI_lAHOCf--fM4BKOL_zgixc9c","labels":["area/k8s","v1-mvp","area/data"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Done","title":"feat(k8s): deploy Redis in data namespace (queue/buffer) + wiring for apps"},{"assignees":["ClementV78"],"content":{"body":"v1 MVP: Prometheus scrapes /metrics from services and Grafana dashboards for ingestion/processing health. No CloudWatch.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #7 (k3s cluster).\n","number":10,"repository":"ClementV78/CloudRadar","title":"feat(k8s): deploy Prometheus + Grafana (observability namespace) with starter dashboards","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/10"},"id":"PVTI_lAHOCf--fM4BKOL_zgixdCs","labels":["area/k8s","v1-mvp","area/observability"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(k8s): deploy Prometheus + Grafana (observability namespace) with starter dashboards"},{"assignees":["ClementV78"],"content":{"body":"### Goal\nProvision the storage foundation for SQLite persistence and backups.\n\n### Scope\n- Define the storage baseline for SQLite (EBS-backed PVC via CSI).\n- Prepare S3 access for backups (bucket + IAM permissions).\n\n### Tasks\n- [ ] Ensure EBS CSI driver is available for k3s\n- [ ] Define StorageClass for SQLite (gp3, single-AZ)\n- [ ] Create/confirm S3 bucket for SQLite backups\n- [ ] Grant k3s node role permission to write to the backup bucket\n\n### DoD\n- EBS StorageClass for SQLite exists\n- Backup bucket available with least-privilege IAM write access\n- Evidence captured (plan/apply + validation)\n\n### Dependencies\n- Depends on #7 (k3s cluster).\n\n### Follow-ups\n- SQLite app + CronJob backup via GitOps tracked in a separate ticket.\n","number":11,"repository":"ClementV78/CloudRadar","title":"feat(data): SQLite storage foundation (EBS + S3 access)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/11"},"id":"PVTI_lAHOCf--fM4BKOL_zgixdHg","labels":["area/infra","v1-mvp","area/data"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Done","title":"feat(data): SQLite storage foundation (EBS + S3 access)"},{"assignees":["ClementV78"],"content":{"body":"Improve scalability and network design by introducing an internal NLB between Edge EC2 and private k3s services. Provides stable endpoint and cleaner separation.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #8 (edge EC2).\n- Depends on #7 (k3s services).\n","number":13,"repository":"ClementV78/CloudRadar","title":"feat(edge): replace NodePort with internal NLB (edge -> k3s)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/13"},"id":"PVTI_lAHOCf--fM4BKOL_zgixog0","labels":["area/infra","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"M","status":"Backlog","title":"feat(edge): replace NodePort with internal NLB (edge -> k3s)"},{"assignees":["ClementV78"],"content":{"body":"Use ACM certificates and Route53 DNS instead of manual TLS handling. Cleaner and more production-like setup.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #8 (edge EC2).\n- Requires a registered domain and Route53 hosted zone.\n","number":14,"repository":"ClementV78/CloudRadar","title":"feat(edge): migrate TLS to ACM + Route53","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/14"},"id":"PVTI_lAHOCf--fM4BKOL_zgixog8","labels":["area/infra","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(edge): migrate TLS to ACM + Route53"},{"assignees":["ClementV78"],"content":{"body":"Adopt GitOps workflow for Kubernetes manifests and Helm charts using Argo CD. Improve deployment traceability and portfolio maturity.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #7 (k3s cluster).\n","number":15,"repository":"ClementV78/CloudRadar","title":"feat(k8s): introduce GitOps with Argo CD","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/15"},"id":"PVTI_lAHOCf--fM4BKOL_zgixohA","labels":["area/k8s","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"L","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(k8s): introduce GitOps with Argo CD"},{"assignees":["ClementV78"],"content":{"body":"Deploy ingress controller and cert-manager for in-cluster traffic management and TLS automation.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #7 (k3s cluster).\n","number":16,"repository":"ClementV78/CloudRadar","title":"feat(k8s): ingress controller + cert-manager","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/16"},"id":"PVTI_lAHOCf--fM4BKOL_zgixohE","labels":["area/k8s","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(k8s): ingress controller + cert-manager"},{"assignees":["ClementV78"],"content":{"body":"Add alerting on key metrics (node down, pod crashloop, disk pressure). Improves operational maturity with minimal cost.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #10 (Prometheus/Grafana).\n","number":17,"repository":"ClementV78/CloudRadar","title":"feat(obs): add alerting via Alertmanager","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/17"},"id":"PVTI_lAHOCf--fM4BKOL_zgixohI","labels":["area/observability","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(obs): add alerting via Alertmanager"},{"assignees":["ClementV78"],"content":{"body":"Introduce centralized logging using Loki and Promtail. Provides production-like observability without heavy infra.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #7 (k3s cluster).\n","number":18,"repository":"ClementV78/CloudRadar","title":"feat(obs): centralize logs with Loki + Promtail","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/18"},"id":"PVTI_lAHOCf--fM4BKOL_zgixohM","labels":["area/observability","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(obs): centralize logs with Loki + Promtail"},{"assignees":["ClementV78"],"content":{"body":"Replace custom backup logic with Velero for Kubernetes resources and volumes backups to S3.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #11 (S3 backups baseline).\n","number":19,"repository":"ClementV78/CloudRadar","title":"feat(data): standardize k8s backups with Velero","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/19"},"id":"PVTI_lAHOCf--fM4BKOL_zgixohQ","labels":["area/data","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(data): standardize k8s backups with Velero"},{"assignees":["ClementV78"],"content":{"body":"Introduce lifecycle and retention policies on S3 backups (e.g. transition to Glacier) to optimize storage costs.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #11 (S3 backups baseline).\n","number":20,"repository":"ClementV78/CloudRadar","title":"feat(data): add S3 lifecycle policies for backups","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/20"},"id":"PVTI_lAHOCf--fM4BKOL_zgixohY","labels":["area/data","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"S","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(data): add S3 lifecycle policies for backups"},{"assignees":["ClementV78"],"content":{"body":"Add a clean multi-environment layout (e.g., infra/live/v1 and infra/live/v2) composing shared local modules. No need to deploy v2 now; structure + wiring is enough.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #6 (remote backend config).\n","number":21,"repository":"ClementV78/CloudRadar","title":"feat(infra): introduce multi-env Terraform structure (v1 / v2)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/21"},"id":"PVTI_lAHOCf--fM4BKOL_zgixohc","labels":["area/infra","v1.1","p0"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P0","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(infra): introduce multi-env Terraform structure (v1 / v2)"},{"assignees":["ClementV78"],"content":{"body":"Introduce baseline NetworkPolicies (default-deny where relevant + explicit allow rules). Note: feasibility depends on the CNI used by k3s; document the chosen approach.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #7 (k3s cluster).\n","number":22,"repository":"ClementV78/CloudRadar","title":"feat(k8s): add NetworkPolicies baseline","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/22"},"id":"PVTI_lAHOCf--fM4BKOL_zgixoho","labels":["area/k8s","v1.1","p2"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(k8s): add NetworkPolicies baseline"},{"assignees":["ClementV78"],"content":{"body":"Add basic distributed tracing to complement metrics/logs. Keep scope minimal (single service instrumentation + collector + UI) for portfolio relevance.\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #7 (k3s cluster).\n- Depends on #5 (app service to instrument).\n","number":23,"repository":"ClementV78/CloudRadar","title":"feat(obs): introduce basic tracing (Tempo or Jaeger)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/23"},"id":"PVTI_lAHOCf--fM4BKOL_zgixohw","labels":["area/observability","v1.1","p3"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"M","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(obs): introduce basic tracing (Tempo or Jaeger)"},{"assignees":["ClementV78"],"content":{"body":"Document and automate a restore workflow (job/script/runbook) and add a repeatable restore test to validate backups are usable (not just created).\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #11 (S3 backups baseline).\n","number":25,"repository":"ClementV78/CloudRadar","title":"feat(data): automate restore workflow + add restore test","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/25"},"id":"PVTI_lAHOCf--fM4BKOL_zgixoh4","labels":["area/data","v1.1","p1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"S","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(data): automate restore workflow + add restore test"},{"assignees":["ClementV78"],"content":{"body":"Goal (v1.1): reduce cost and reliance on NAT/Internet without replatforming.\n\nPhase 1 (must-have, low risk, likely cost win):\n- Add S3 Gateway VPC Endpoint\n- Update route tables for private subnets to use the S3 endpoint\n- Validate: backups to S3 work from private workloads without NAT data path\n\n\nDoD:\n- S3 traffic from private subnet no longer requires NAT/Internet\n\n### üèÅ DoD\n- Implementation complete and reviewed\n- CI checks green\n- Docs/README/ADR updated if needed\n- Deploy/plan/test evidence captured when relevant\n\n## Dependencies\n- Depends on #1 (VPC).\n- Depends on #11 (S3 backups baseline).\n","number":30,"repository":"ClementV78/CloudRadar","title":"feat(infra): add VPC endpoints (S3 Gateway first) to reduce NAT/Internet egress","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/30"},"id":"PVTI_lAHOCf--fM4BKOL_zgjYfOw","labels":["area/infra","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","size":"S","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(infra): add VPC endpoints (S3 Gateway first) to reduce NAT/Internet egress"},{"content":{"body":"Deliver v1-mvp infrastructure and core services (VPC, k3s, edge, Redis, SQLite backups, Prometheus/Grafana) for a first end-to-end demo.","id":"DI_lAHOCf--fM4BKOL_zgKC1eM","title":"Sprint 2 Goal","type":"DraftIssue"},"id":"PVTI_lAHOCf--fM4BKOL_zgjZT2A","sprint":{"duration":14,"iterationId":"9b37ee5b","startDate":"2026-01-01","title":"Sprint 2"},"title":"Sprint 2 Goal"},{"content":{"body":"Deliver v1.1 hardening and platform polish (multi-env, edge improvements, backups, security policies, ingress, GitOps, logs/alerts/tracing).","id":"DI_lAHOCf--fM4BKOL_zgKC1fE","title":"Sprint 3 Goal","type":"DraftIssue"},"id":"PVTI_lAHOCf--fM4BKOL_zgjZUMs","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"title":"Sprint 3 Goal"},{"assignees":["ClementV78"],"content":{"body":"## Context\nWe need a secure AWS account baseline and GitHub OIDC access to run infra automation without static keys.\n\n## Tasks\n- Create AWS account for CloudRadar.\n- Enable MFA on root and lock down root usage.\n- Configure billing alerts and cost visibility.\n- Create IAM OIDC provider for GitHub Actions (repo: ClementV78/CloudRadar).\n- Create IAM role for CI with least-privilege permissions for infra bootstrap and Terraform plan/apply.\n- Document required AWS account settings and role ARN in README or docs/runbooks.\n\n## DoD\n- Root account protected (MFA enabled, no access keys).\n- GitHub OIDC provider exists and is bound to this repo.\n- CI role exists with least-privilege policy and trust policy documented.\n- Setup steps documented.\n\n## Defaults\n- Role name: `CloudRadarTerraformRole`\n- OIDC provider tag/name: `github-actions-oidc`\n- Budget alert threshold: $10/month (AWS Budgets)\n\n","number":32,"repository":"ClementV78/CloudRadar","title":"feat(infra): bootstrap aws account and github oidc access","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/32"},"id":"PVTI_lAHOCf--fM4BKOL_zgjcHaI","labels":["area/infra","kind/maintenance","v1-mvp","p0"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/34"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","sprint":{"duration":14,"iterationId":"9b37ee5b","startDate":"2026-01-01","title":"Sprint 2"},"status":"Done","title":"feat(infra): bootstrap aws account and github oidc access"},{"assignees":["ClementV78"],"content":{"body":"## Context\nTerraform remote state requires S3 + DynamoDB. We want to bootstrap these resources via CI using a temporary local Terraform state and OIDC (no static keys).\n\n## Tasks\n- Add a GitHub Actions workflow that runs Terraform with a local backend (ephemeral state) to create the S3 bucket and DynamoDB table for state/locking.\n- Ensure the workflow is idempotent and avoids destructive changes.\n- Store backend identifiers (bucket name, table name, region) in a reusable form (repo variables or documented config).\n- Verify the workflow uses OIDC to assume the CI role.\n\n## Dependencies\n- Depends on #32 (AWS account baseline + GitHub OIDC role).\n- Blocks #6 (Terraform backend config usage).\n\n## DoD\n- Workflow runs with OIDC and creates S3 + DynamoDB when missing.\n- Workflow is idempotent.\n- Backend identifiers are documented or stored for reuse by infra Terraform.","number":33,"repository":"ClementV78/CloudRadar","title":"ci(infra): bootstrap terraform backend via github actions","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/33"},"id":"PVTI_lAHOCf--fM4BKOL_zgjcHco","labels":["area/infra","kind/maintenance","v1-mvp","p0"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/35"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","sprint":{"duration":14,"iterationId":"9b37ee5b","startDate":"2026-01-01","title":"Sprint 2"},"status":"Done","title":"ci(infra): bootstrap terraform backend via github actions"},{"assignees":["ClementV78"],"content":{"body":"Create EKS foundation (VPC wiring, cluster, nodegroup(s)) using Terraform. Scope: minimal working cluster + access + baseline outputs. Keep addons minimal initially.\n\n## Dependencies\n- Depends on #27 (multi-AZ VPC refactor).\n","number":26,"repository":"ClementV78/CloudRadar","title":"feat(v2): EKS cluster foundation with Terraform","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/26"},"id":"PVTI_lAHOCf--fM4BKOL_zgjcJFA","labels":["area/infra","v2"],"milestone":{"description":"","dueOn":"","title":"v2"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"feat(v2): EKS cluster foundation with Terraform"},{"assignees":["ClementV78"],"content":{"body":"Refactor VPC to multi-AZ: at least 2 AZs with public + private subnets, proper route tables, and spread nodegroups across AZs.\n\n## Dependencies\n- Blocks #26 (EKS foundation).\n","number":27,"repository":"ClementV78/CloudRadar","title":"feat(v2): multi-AZ network layout (public + private subnets) for HA","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/27"},"id":"PVTI_lAHOCf--fM4BKOL_zgjcJGE","labels":["area/infra","v2"],"milestone":{"description":"","dueOn":"","title":"v2"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"feat(v2): multi-AZ network layout (public + private subnets) for HA"},{"assignees":["ClementV78"],"content":{"body":"Define a production-like baseline: >=3 workers, pod disruption budgets for key components, and demonstrate rolling updates without downtime (as much as possible for MVP apps).\n\n## Dependencies\n- Depends on #26 (EKS foundation).\n","number":28,"repository":"ClementV78/CloudRadar","title":"feat(v2): HA baseline with 3 worker nodes + safe rolling updates","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/28"},"id":"PVTI_lAHOCf--fM4BKOL_zgjcJHE","labels":["area/k8s","v2"],"milestone":{"description":"","dueOn":"","title":"v2"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"feat(v2): HA baseline with 3 worker nodes + safe rolling updates"},{"assignees":["ClementV78"],"content":{"body":"Enable IAM Roles for Service Accounts (IRSA) and wire at least one workload to AWS services (e.g., S3 backups) using minimal IAM policies.\n\n## Dependencies\n- Depends on #26 (EKS foundation).\n","number":29,"repository":"ClementV78/CloudRadar","title":"feat(v2): enable IRSA and least-privilege IAM for workloads","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/29"},"id":"PVTI_lAHOCf--fM4BKOL_zgjcJII","labels":["area/infra","area/k8s","v2"],"milestone":{"description":"","dueOn":"","title":"v2"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"feat(v2): enable IRSA and least-privilege IAM for workloads"},{"assignees":["ClementV78"],"content":{"body":"### Decision\nUse **us-east-1** as the default AWS region.\n\n### Rationale\n- Lower cost baseline\n- CloudFront will mitigate latency for end users\n\n### Guidance\n- In issues/specs, use the placeholder `<region>` instead of a hard-coded region.\n- Update infra defaults/docs to resolve `<region>` to **us-east-1**.","number":31,"repository":"ClementV78/CloudRadar","title":"docs(adr): target AWS region (us-east-1)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/31"},"id":"PVTI_lAHOCf--fM4BKOL_zgjcJnM","labels":["documentation","area/docs","v1-mvp"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"docs(adr): target AWS region (us-east-1)"},{"assignees":["ClementV78"],"content":{"body":"### üéØ Objective\nProvide a manual demo workflow to deploy a fresh environment and optionally destroy it with a backup step, so demos can be spun up on demand with minimal cost.\n\n### ‚öôÔ∏è Scope\n- Workflow A (manual): deploy fresh infra, optional destroy with backup.\n- Applies Terraform root: `infra/aws/live/<env>`.\n\n### üß© Dependencies\n- Depends on #11 for backup capability (SQLite ‚Üí S3).\n- Related to #4 (CI plan/validate) and #25 (restore flow).\n\n### ‚úÖ Tasks\n- [ ] Add workflow `demo-deploy.yml` with `workflow_dispatch`.\n- [ ] Inputs: `environment` (dev/prod), `auto_approve` (true/false), `do_destroy` (true/false), `backup_before_destroy` (true/false).\n- [ ] Apply infra for selected env (`terraform init/validate/plan/apply`).\n- [ ] If `do_destroy=true`: run backup step (when `backup_before_destroy=true`), then `terraform destroy`.\n- [ ] Document usage and required repo vars in README/runbook.\n\n### üèÅ DoD\n- Workflow can deploy `dev` and `prod` on demand.\n- Destroy path works and triggers backup when requested.\n- No apply/destroy runs without explicit confirmation inputs.\n\n","number":44,"repository":"ClementV78/CloudRadar","title":"ci(infra): demo workflow A (deploy fresh + optional destroy)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/44"},"id":"PVTI_lAHOCf--fM4BKOL_zgjfVC8","labels":["area/infra","kind/maintenance","area/data"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"ci(infra): demo workflow A (deploy fresh + optional destroy)"},{"assignees":["ClementV78"],"content":{"body":"### üéØ Objective\nProvide a manual demo workflow that deploys infra and restores data from a selected backup, so demos can resume from a previous state on demand.\n\n### ‚öôÔ∏è Scope\n- Workflow B (manual): deploy + restore.\n- Applies Terraform root: `infra/aws/live/<env>`.\n- Restore step uses a provided backup identifier/key.\n\n### üß© Dependencies\n- Depends on #11 (backup format) and #25 (restore workflow).\n- Related to #44 (workflow A deploy/destroy).\n\n### ‚úÖ Tasks\n- [ ] Add workflow `demo-restore.yml` with `workflow_dispatch`.\n- [ ] Inputs: `environment` (dev/prod), `auto_approve` (true/false), `backup_id` (or S3 key).\n- [ ] Apply infra for selected env (`terraform init/validate/plan/apply`).\n- [ ] Restore data from the provided backup.\n- [ ] Optional verification step (service health, data check).\n- [ ] Document usage and required repo vars in README/runbook.\n\n### üèÅ DoD\n- Workflow can deploy `dev` and `prod` on demand.\n- Restore step loads data from a selected backup.\n- No apply runs without explicit confirmation inputs.\n\n","number":45,"repository":"ClementV78/CloudRadar","title":"ci(infra): demo workflow B (deploy + restore)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/45"},"id":"PVTI_lAHOCf--fM4BKOL_zgjfVE0","labels":["area/infra","kind/maintenance","area/data"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"ci(infra): demo workflow B (deploy + restore)"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nAdd a dedicated GitHub Actions workflow to destroy Terraform environments via workflow_dispatch, with explicit confirmations and environment selection.\n\n## Details\n- Create a new workflow (separate from apply) to reduce risk.\n- Require explicit confirmation input (e.g. \"DESTROY\").\n- Support env selection (dev/prod) and guard prod.\n- Reuse the existing Terraform backend config + OIDC role used in the infra workflow.\n\n## References\n- Existing infra workflow: https://github.com/ClementV78/CloudRadar/blob/main/.github/workflows/ci-infra.yml\n- Runbooks order: https://github.com/ClementV78/CloudRadar/blob/main/docs/runbooks/README.md\n\n## Dependencies\n- Related to the current infra apply workflow (link above).\n\n## DoD\n- [ ] Workflow exists and is manual (workflow_dispatch).\n- [ ] Destroy requires explicit confirmation input.\n- [ ] Documentation updated (README or runbook) with usage.\n- [ ] Verified on a branch (no actual destroy in prod).\n","number":48,"repository":"ClementV78/CloudRadar","title":"ci(infra): add terraform destroy workflow","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/48"},"id":"PVTI_lAHOCf--fM4BKOL_zgjiMkY","labels":["area/infra","kind/maintenance","v1.1","p2"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/59"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"ci(infra): add terraform destroy workflow"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nDocument the `ci-infra` GitHub Actions workflow to explain PR checks and manual apply behavior.\n\n## Details\n- Add a runbook dedicated to `ci-infra`.\n- Link it from the runbooks index.\n- Keep documentation aligned with current workflow inputs and repo variables.\n\n## References\n- Workflow: https://github.com/ClementV78/CloudRadar/blob/main/.github/workflows/ci-infra.yml\n- Runbooks index: https://github.com/ClementV78/CloudRadar/blob/main/docs/runbooks/README.md\n- Related issue: https://github.com/ClementV78/CloudRadar/issues/1\n\n## DoD\n- [ ] Runbook exists and describes PR checks + workflow_dispatch apply.\n- [ ] Runbooks index links to the new runbook.\n","number":50,"repository":"ClementV78/CloudRadar","title":"docs(runbooks): add ci-infra runbook","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/50"},"id":"PVTI_lAHOCf--fM4BKOL_zgjiR5I","labels":["documentation","area/docs","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/51"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"docs(runbooks): add ci-infra runbook"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nFix README links to be clickable and remove the duplicate Decision Records section.\n\n## Details\n- Convert runbook/document references to Markdown links.\n- Keep a single references section for decisions.\n\n## References\n- README: https://github.com/ClementV78/CloudRadar/blob/main/README.md\n\n## DoD\n- [ ] README links are clickable.\n- [ ] Duplicate Decision Records section removed.\n","number":52,"repository":"ClementV78/CloudRadar","title":"docs(readme): fix README links and remove duplicate section","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/52"},"id":"PVTI_lAHOCf--fM4BKOL_zgjiT9g","labels":["documentation","area/docs","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/53"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"docs(readme): fix README links and remove duplicate section"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nTrack all AGENTS.md changes in a single meta issue to avoid ticket noise.\n\n## Usage\n- Link every AGENTS.md PR to this issue.\n- Update this issue with a short changelog for each AGENTS.md update.\n- Do not open new issues for AGENTS.md-only changes.\n\n## DoD\n- [ ] Each AGENTS.md PR references this meta issue.\n- [ ] This issue is updated with a brief changelog entry per update.\n","number":55,"repository":"ClementV78/CloudRadar","title":"docs(meta): AGENTS.md updates","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/55"},"id":"PVTI_lAHOCf--fM4BKOL_zgjiZg4","labels":["documentation","area/docs","v1-mvp"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"docs(meta): AGENTS.md updates"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nTrack README and documentation maintenance in a single meta issue to reduce ticket noise.\n\n## Usage\n- Link every docs-only PR (README/runbooks/architecture) to this issue.\n- Add a short changelog entry to this issue for each docs update.\n- Do not open new issues for docs-only changes unless they are feature-level.\n\n## DoD\n- [ ] Each docs-only PR references this meta issue.\n- [ ] This issue is updated with a brief changelog entry per update.\n","number":57,"repository":"ClementV78/CloudRadar","title":"docs(meta): docs maintenance (README + runbooks)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/57"},"id":"PVTI_lAHOCf--fM4BKOL_zgjiaec","labels":["documentation","area/docs","v1-mvp"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"docs(meta): docs maintenance (README + runbooks)"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nFix the manual apply job in `ci-infra` to pass required Terraform variables so applies do not fail.\n\n## Details\n- Use the example tfvars file for validate/plan/apply in workflow_dispatch.\n- Update the CI runbook to reflect the behavior.\n\n## References\n- Workflow: https://github.com/ClementV78/CloudRadar/blob/main/.github/workflows/ci-infra.yml\n- Runbook: https://github.com/ClementV78/CloudRadar/blob/main/docs/runbooks/ci-infra.md\n\n## DoD\n- [ ] Manual apply works without missing variables.\n- [ ] Runbook updated.\n","number":61,"repository":"ClementV78/CloudRadar","title":"ci(infra): fix apply to use tfvars in workflow_dispatch","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/61"},"id":"PVTI_lAHOCf--fM4BKOL_zgjiomw","labels":["area/infra","kind/maintenance","v1-mvp","p1"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/62"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"ci(infra): fix apply to use tfvars in workflow_dispatch"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nAdd a least-privilege baseline IAM policy for `CloudRadarTerraformRole` (MVP) and consolidate IAM guidance into a single runbook section.\n\n## Details\n- Merge IAM policy guidance into `docs/runbooks/aws-account-bootstrap.md` and remove `docs/runbooks/iam-terraform-role-policy.md`.\n- Document how GitHub Actions uses OIDC to assume the role, and how AWS CLI uses a local IAM user profile + assume-role.\n- Define the MVP infra scope (VPC, EC2, EBS, SG, IGW, routes, tags, S3 backups as needed) based on MVP tickets + architecture diagram.\n- Provide the policy JSON and CLI command to attach it to `CloudRadarTerraformRole`.\n\n## References\n- Runbook: https://github.com/ClementV78/CloudRadar/blob/main/docs/runbooks/aws-account-bootstrap.md\n- IAM policy doc (to be removed): https://github.com/ClementV78/CloudRadar/blob/main/docs/runbooks/iam-terraform-role-policy.md\n- Diagram: https://github.com/ClementV78/CloudRadar/blob/main/docs/architecture/cloudradar-v1-high-level.png\n\n## DoD\n- [ ] Single IAM MVP runbook section in aws-account-bootstrap.\n- [ ] Baseline policy defined and attached to `CloudRadarTerraformRole`.\n- [ ] Explanation of AWS CLI vs GitHub Actions auth paths included.\n- [ ] Apply works for dev VPC after policy update.\n","number":63,"repository":"ClementV78/CloudRadar","title":"feat(infra): add baseline IAM policy for Terraform role","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/63"},"id":"PVTI_lAHOCf--fM4BKOL_zgjjj8Q","labels":["area/infra","kind/maintenance","v1-mvp","p1"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/64"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"feat(infra): add baseline IAM policy for Terraform role"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nWorkflow apply fails because terraform validate receives -var-file. Remove the flag from validate step in ci-infra apply job.\n\n## DoD\n- [ ] ci-infra apply validate runs without -var-file\n- [ ] Workflow succeeds on branch via workflow_dispatch\n- [ ] README/runbook update only if required\n","number":71,"repository":"ClementV78/CloudRadar","title":"fix(ci): remove var-file from terraform validate","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/71"},"id":"PVTI_lAHOCf--fM4BKOL_zgjlt7A","labels":["bug","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/72"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"fix(ci): remove var-file from terraform validate"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nDestroy workflow fails due to missing required variables. Pass terraform.tfvars.example to the destroy step.\n\n## DoD\n- [ ] ci-infra-destroy uses -var-file for destroy\n- [ ] workflow_dispatch destroy succeeds on branch\n- [ ] docs updated only if needed\n","number":73,"repository":"ClementV78/CloudRadar","title":"fix(ci): pass tfvars to destroy","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/73"},"id":"PVTI_lAHOCf--fM4BKOL_zgjmCnc","labels":["bug","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/74"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"fix(ci): pass tfvars to destroy"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nImprove the AGENTS update script to handle auto-merge failures: retry on UNKNOWN merge state, log details, and fallback to manual squash merge.\n\n## DoD\n- [ ] Script retries when mergeStateStatus is UNKNOWN\n- [ ] Script logs merge state/auto-merge availability\n- [ ] Script falls back to gh pr merge --squash when auto-merge fails\n","number":76,"repository":"ClementV78/CloudRadar","title":"refactor(agents): harden auto-merge handling","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/76"},"id":"PVTI_lAHOCf--fM4BKOL_zgjmEA8","labels":["kind/maintenance","skill"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/77"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"refactor(agents): harden auto-merge handling"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nImprove AGENTS update automation: retry UNKNOWN merge state, log merge status, and fall back to direct squash merge when auto-merge fails.\n\n## Testing\n- Not run (script change).\n\nFixes #76\n\nRefs #55\n","number":77,"repository":"ClementV78/CloudRadar","title":"refactor(agents): harden auto-merge","type":"PullRequest","url":"https://github.com/ClementV78/CloudRadar/pull/77"},"id":"PVTI_lAHOCf--fM4BKOL_zgjmKgA","labels":["kind/maintenance","skill"],"repository":"https://github.com/ClementV78/CloudRadar","title":"refactor(agents): harden auto-merge"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nAdd a git backup helper script that tags releases based on project name + milestone + date, creates a git bundle, and verifies integrity.\n\n## Scope\n- Script lives under `scripts/git-backup.sh`\n- Generates tag `<project>-<milestone>-<YYYY-MM-DD>`\n- Creates bundle `backups/<tag>.bundle` and verifies it\n- Adds `backups/*.bundle` to .gitignore\n\n## DoD\n- Script exists and is executable\n- Tag + bundle + verify flow documented in script usage\n- .gitignore updated to exclude bundles\n","number":94,"repository":"ClementV78/CloudRadar","title":"feat(meta): add git backup bundle script","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/94"},"id":"PVTI_lAHOCf--fM4BKOL_zgjrYKw","labels":["kind/maintenance"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/95"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"feat(meta): add git backup bundle script"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nAdd a minimal health endpoint exposed through the edge Nginx to validate end-to-end connectivity to k3s and return non-sensitive cluster aggregates (nodes ready/total, apps count, CPU/RAM if metrics are available).\n\n## Scope\n- Health service deployed via GitOps (ArgoCD) under `k8s/apps`.\n- Read-only RBAC for cluster aggregates.\n- Ingress for `/healthz` via Traefik.\n- Edge Nginx routing for `/healthz` with Basic Auth.\n- Documentation update (runbook/notes) for verification.\n\n## Out of Scope\n- Full observability stack.\n- Public ArgoCD exposure.\n\n## DoD\n- `/healthz` returns JSON with non-sensitive cluster aggregates.\n- Edge Nginx routes `/healthz` to k3s and is protected by Basic Auth.\n- GitOps manifests committed under `k8s/apps`.\n- Verification steps documented.\n","number":97,"repository":"ClementV78/CloudRadar","title":"feat(k8s): expose health endpoint via edge","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/97"},"id":"PVTI_lAHOCf--fM4BKOL_zgjyioI","labels":["enhancement","area/infra","area/k8s","p1"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/101"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"feat(k8s): expose health endpoint via edge"},{"assignees":["ClementV78"],"content":{"body":"## Summary\nAdd a minimal ArgoCD bootstrap script (SSM) and runbook to install ArgoCD and register the GitOps app path.\n\n## Scope\n- `scripts/bootstrap-argocd.sh` to install ArgoCD and create the Application.\n- Runbook with prerequisites, steps, and verification.\n\n## Out of Scope\n- Full ArgoCD exposure via ingress.\n- ArgoCD HA install variant.\n\n## DoD\n- Script installs ArgoCD and creates the GitOps Application.\n- Runbook documents prerequisites and commands.\n- Changes land in a single tooling PR.\n","number":98,"repository":"ClementV78/CloudRadar","title":"feat(tooling): add ArgoCD bootstrap script","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/98"},"id":"PVTI_lAHOCf--fM4BKOL_zgjzcGw","labels":["area/infra","area/docs","kind/maintenance","p2"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/99"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"feat(tooling): add ArgoCD bootstrap script"},{"assignees":["ClementV78"],"content":{"body":"## Context\nCI smoke test curls `/healthz` via Edge Basic Auth. The variable `edge_allowed_cidrs` already existed in the dev tfvars example, but the value was too restrictive and blocked GitHub Actions runner IPs, causing the smoke test to fail.\n\nRun: https://github.com/ClementV78/CloudRadar/actions/runs/21114132963\n\n## Scope\n- Update `infra/aws/live/dev/terraform.tfvars.example` to set `edge_allowed_cidrs = [\"0.0.0.0/0\"]` for CI access in dev.\n\n## DoD\n- [ ] `edge_allowed_cidrs` example value updated for dev.\n- [ ] PR links back to this issue.\n","number":106,"repository":"ClementV78/CloudRadar","title":"fix(infra): allow dev edge CIDR for CI smoke tests","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/106"},"id":"PVTI_lAHOCf--fM4BKOL_zgj2Hio","labels":["bug","area/infra","v1-mvp","p1","kind/ci"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/107"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Done","title":"fix(infra): allow dev edge CIDR for CI smoke tests"},{"assignees":["ClementV78"],"content":{"body":"### Goal\nIngest flight telemetry from OpenSky and push events into Redis (queue/buffer) for the v1 pipeline.\n\n### Specs (v1)\n- **Source:** OpenSky public API (rate-limited)\n- **Output:** Redis list/stream used by the processor\n- **Observability:** expose `/metrics` for Prometheus\n- **K8s:** Deployment + Service, probes, resources\n\n### Tasks\n- [ ] Scaffold ingester service under `src/ingester`\n- [ ] Implement OpenSky fetch + transform (minimal schema)\n- [ ] Push events to Redis with backoff on rate limits\n- [ ] Container build (Dockerfile or equivalent)\n- [ ] Manifests `k8s/apps/ingester/base` (deployment + service)\n- [ ] Add readiness/liveness probes\n- [ ] Add requests/limits\n- [ ] Expose `/metrics` and ensure Prometheus can scrape it\n\n### DoD\n- OpenSky ingestion works with example env\n- Events land in Redis and are consumable by the processor\n- Deploy OK on k3s\n- `/metrics` reachable via curl (Prometheus validation optional until #10)\n\n### Validation Steps\n- Confirm `/metrics` responds via a manual HTTP check.\n- If #10 is available, confirm Prometheus scraping is active.\n\n### Dependencies\n- Depends on #7 (k3s cluster).\n- Depends on #9 (Redis).\n- Optional: #10 (Prometheus/Grafana) for /metrics validation (manual curl accepted before #10).\n\n## Follow-ups\n- #128 (zones + alerting)\n- #129 (dashboard API)\n- #130 (frontend dashboard)\n","number":111,"repository":"ClementV78/CloudRadar","title":"feat(app): init OpenSky Ingester & Redis pipeline","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/111"},"id":"PVTI_lAHOCf--fM4BKOL_zgj5BXU","labels":["area/app","v1-mvp","area/data"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/136"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Done","title":"feat(app): init OpenSky Ingester & Redis pipeline"},{"assignees":["ClementV78"],"content":{"body":"### Goal\nMigrate Redis from the default `local-path` StorageClass to an EBS-backed StorageClass for improved durability in v1.1.\n\n### Scope\n- Install/enable the EBS CSI driver if not already present.\n- Define a StorageClass suitable for Redis (gp3, single-AZ).\n- Update Redis StatefulSet `volumeClaimTemplates` to use the new StorageClass.\n- Validate PVC binding and Redis readiness.\n\n### Tasks\n- [ ] Add/verify EBS CSI driver\n- [ ] Create StorageClass (gp3) for Redis\n- [ ] Update Redis PVC to use the new StorageClass\n- [ ] Validate Redis on k3s (pod ready + PONG)\n\n### DoD\n- Redis uses EBS-backed PVCs\n- PVC bound to the new StorageClass\n- Redis responds to `PING`\n\n### Dependencies\n- Depends on #7 (k3s cluster).\n- Related to #9 (Redis deployment).\n","number":112,"repository":"ClementV78/CloudRadar","title":"feat(data): move Redis storage to EBS CSI","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/112"},"id":"PVTI_lAHOCf--fM4BKOL_zgj50uY","labels":["area/k8s","area/data","v1.1"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"repository":"https://github.com/ClementV78/CloudRadar","sprint":{"duration":14,"iterationId":"b68a7ebc","startDate":"2026-01-29","title":"Sprint 4"},"status":"Backlog","title":"feat(data): move Redis storage to EBS CSI"},{"assignees":["ClementV78"],"content":{"body":"### Goal\nAdd a local script to detect stale/behind branches and emit a summary alert file for VS Code notifications.\n\n### Scope\n- Script outputs a summary alert file under `.local/alerts/`.\n- Uses `gh` (if available) to detect merged PRs and commits after merge.\n- Ignore branches already merged into `origin/main`.\n\n### DoD\n- Script produces a single summary alert file.\n- Local alerts path is ignored by git.\n- Documentation updated if needed.\n\n### Notes\n- Intended for local developer workflow (no CI usage).\n","number":115,"repository":"ClementV78/CloudRadar","title":"feat(tooling): add local branch alert script","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/115"},"id":"PVTI_lAHOCf--fM4BKOL_zgj57bo","labels":["kind/maintenance"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/116"],"repository":"https://github.com/ClementV78/CloudRadar","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Done","title":"feat(tooling): add local branch alert script"},{"assignees":["ClementV78"],"content":{"body":"### Goal\nDeploy SQLite in k3s with a PVC and schedule daily backups to S3 via a CronJob.\n\n### Scope\n- SQLite StatefulSet + PVC in the `data` namespace.\n- CronJob to back up the SQLite database to S3.\n- Restore procedure documented.\n\n### Tasks\n- [ ] Create SQLite StatefulSet + PVC manifests\n- [ ] Add Service if needed for access\n- [ ] Add CronJob for daily backups to S3\n- [ ] Document restore steps\n\n### DoD\n- SQLite pod is running with PVC bound\n- Backup CronJob runs and uploads to S3\n- Restore steps documented and verified\n\n### Dependencies\n- Depends on #7 (k3s cluster).\n- Depends on #11 (SQLite storage foundation).\n","number":117,"repository":"ClementV78/CloudRadar","title":"feat(k8s): deploy SQLite + daily S3 backups","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/117"},"id":"PVTI_lAHOCf--fM4BKOL_zgj6C0k","labels":["area/k8s","v1-mvp","area/data"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","sprint":{"duration":14,"iterationId":"2ed2961d","startDate":"2026-01-15","title":"Sprint 3"},"status":"Backlog","title":"feat(k8s): deploy SQLite + daily S3 backups"},{"content":{"body":"## Goal\nImplement exclusion zones and alerting for the IDF territory using OpenSky data already ingested into Redis.\n\n## Scope\n- Define a simple zones config format (JSON/YAML) committed in repo (example + template).\n- Warning when aircraft approaches a zone (distance threshold).\n- Alert when aircraft enters a zone (polygon intersection).\n- Alerting loop runs every 60s (backend cadence).\n- Emit events to Redis (stream/list) for dashboard consumption.\n\n## DoD\n- Zones config is versioned with a documented schema and example.\n- Alerting worker reads latest aircraft positions from Redis (from #5 aggregates).\n- Warning + alert events are produced and testable.\n- Basic logs/metrics show number of warnings/alerts per cycle.\n\n## Dependencies\n- Depends on #111 (OpenSky ingestion to Redis).\n- Depends on #5 (processor aggregates: last position/short track/bbox counter).\n\n## Notes\n- SQLite persistence is not required for v1; Redis aggregates are enough.\n","number":128,"repository":"ClementV78/CloudRadar","title":"feat(app): add exclusion zones + alerting (IDF)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/128"},"id":"PVTI_lAHOCf--fM4BKOL_zgkFe-A","labels":["area/app","v1-mvp","area/data"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"feat(app): add exclusion zones + alerting (IDF)"},{"assignees":["ClementV78"],"content":{"body":"## Context\nEdge bootstrap can fail when network access to VPC endpoints is not ready. Add a CI sanity check to validate subnet/SG/NACL/ENI connectivity assumptions before running edge smoke tests.\n\n## Scope\n- Collect and assert the edge subnet, SG, NACL, and endpoint ENI wiring from AWS CLI in CI.\n- Fail early with clear diagnostics when expected rules or attachments are missing.\n- Keep checks read-only (no changes to infra).\n\n## Dependencies\n- Relies on AWS credentials in CI and existing outputs for subnet/SG/endpoint IDs.\n\n## DoD\n- [ ] CI job reports subnet/SG/NACL/ENI checks with readable output.\n- [ ] CI fails with a clear error if expected network wiring is missing.\n- [ ] Runbook or README updated if new expectations are introduced.\n","number":148,"repository":"ClementV78/CloudRadar","title":"ci(infra): add network sanity checks in edge pipeline","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/148"},"id":"PVTI_lAHOCf--fM4BKOL_zgkNJq0","labels":["enhancement","area/infra","v1.1","p2","kind/ci"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"ci(infra): add network sanity checks in edge pipeline"},{"content":{"body":"## Goal\nExpose a minimal API for the dashboard to query live flights, recent tracks, and alert events.\n\n## Scope\n- API endpoints for:\n  - Latest flights in bbox (IDF).\n  - Recent track for a selected aircraft (short history window).\n  - Latest warning/alert events.\n- Backed by Redis aggregates in v1 (fast, in-memory).\n- SQLite persistence is optional later (see #165).\n- Keep payloads small and cacheable.\n\n## DoD\n- API endpoints documented with example responses.\n- Works end-to-end against local dev data.\n- Ready to be consumed by the frontend.\n\n## Dependencies\n- Depends on #111 (ingestion).\n- Depends on #5 (processor aggregates: last position + short track + bbox counter).\n- Depends on #128 (zones + alerting) for alert events.\n- Optional: #165 (SQLite persistence) for durability beyond v1.\n","number":129,"repository":"ClementV78/CloudRadar","title":"feat(app): add dashboard API (flights + tracks + alerts)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/129"},"id":"PVTI_lAHOCf--fM4BKOL_zgkFe-s","labels":["area/app","v1-mvp"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"feat(app): add dashboard API (flights + tracks + alerts)"},{"content":{"body":"## Goal\nAdd Java code quality + security checks for the ingester/processor to the CI pipeline, and set up dependency/security automation.\n\n## Scope\n- CI workflow for Java (Maven) with:\n  - `mvn -q -DskipTests verify`\n  - SpotBugs\n  - OWASP Dependency-Check\n- CodeQL workflow (repo public)\n- Dependabot config for Maven\n- Optional local developer hooks (documented): pre-commit + gitleaks\n\n## DoD\n- CI workflow added and runs on PRs touching `src/**`.\n- SpotBugs and OWASP Dependency-Check run and surface findings.\n- CodeQL analysis enabled.\n- Dependabot configured for Maven updates.\n- Optional local hooks documented (no hard requirement).\n\n## Notes\n- Keep the pipeline cost-aware and lightweight.\n","number":131,"repository":"ClementV78/CloudRadar","title":"ci(app): add Java quality + security checks","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/131"},"id":"PVTI_lAHOCf--fM4BKOL_zgkFspw","labels":["area/app","v1-mvp","kind/ci"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"ci(app): add Java quality + security checks"},{"content":{"body":"## Goal\nBuild the MVP dashboard UI to visualize air traffic over IDF, zones, and alerts.\n\n## Scope\n- Leaflet map centered on IDF bbox.\n- Aircraft markers with click panel (info + recent track).\n- Render exclusion zones + highlight alerts.\n- Filters: basic type/heuristic (best effort).\n- Refresh every 10s while dashboard is open.\n\n## DoD\n- UI loads on desktop + mobile.\n- Fetches data from the dashboard API.\n- Demonstrable: show alerts when a flight approaches/enters a zone.\n\n## Dependencies\n- Depends on #129 (dashboard API).\n- Depends on #128 (zones + alerting).\n\n","number":130,"repository":"ClementV78/CloudRadar","title":"feat(frontend): Leaflet dashboard (IDF traffic + zones + alerts)","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/130"},"id":"PVTI_lAHOCf--fM4BKOL_zgkFe_c","labels":["area/app","v1-mvp"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"feat(frontend): Leaflet dashboard (IDF traffic + zones + alerts)"},{"content":{"body":"## Goal\nAutomate build and push of all app images to GHCR (ingester, health, admin-scale, processor).\n\n## Scope\n- Single GitHub Actions workflow using a matrix for app builds.\n- Build/push images:\n  - `ghcr.io/clementv78/cloudradar-ingester`\n  - `ghcr.io/clementv78/cloudradar-health`\n  - `ghcr.io/clementv78/cloudradar-admin-scale`\n  - `ghcr.io/clementv78/cloudradar-processor`\n- Triggers:\n  - On changes under `src/<app>/**` (and Dockerfile) via path filters.\n  - Manual `workflow_dispatch` for rebuilds.\n- Tagging:\n  - `latest` on `main`.\n  - `sha` (short SHA) on PRs/branch builds.\n- Keep build steps minimal and cost-aware.\n\n## DoD\n- Workflow builds and pushes images successfully for all apps.\n- GHCR packages updated on main merges.\n- Changes to one app do not rebuild unrelated apps (matrix filter).\n\n## Notes\n- Use GHCR `GITHUB_TOKEN` for auth.\n- Prefer caching to keep build time low.\n","number":132,"repository":"ClementV78/CloudRadar","title":"ci(app): build & push app images to GHCR","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/132"},"id":"PVTI_lAHOCf--fM4BKOL_zgkGAFo","labels":["area/app","v1-mvp","kind/ci"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"ci(app): build & push app images to GHCR"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nReduce flakiness of the k3s-ready-check by adding retry/backoff before failing.\n\n## Scope\n- Update the CI job to retry readiness checks (e.g., 5 attempts with 10‚Äì15s sleep).\n- Log each retry attempt.\n\n## DoD\n- k3s-ready-check retries before failing.\n- CI log shows retry attempts.\n\n","number":133,"repository":"ClementV78/CloudRadar","title":"ci(infra): add retry/backoff to k3s-ready-check","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/133"},"id":"PVTI_lAHOCf--fM4BKOL_zgkGckc","labels":["area/infra","v1-mvp","kind/ci"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/137"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"ci(infra): add retry/backoff to k3s-ready-check"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nConfigure CloudWatch Logs retention to 72h for CloudRadar app logs in namespaces: cloudradar, data, argocd.\n\n## Scope\n- Ensure logs from app pods (cloudradar), data services (data), and ArgoCD (argocd) ship to CloudWatch.\n- Set retention to 72h (3 days) for the relevant log groups.\n- Keep cost-aware defaults (no long retention).\n\n## DoD\n- Log shipping enabled for the three namespaces.\n- CloudWatch log groups show 72h retention.\n- Minimal documentation update (where to find logs + retention policy).\n","number":134,"repository":"ClementV78/CloudRadar","title":"feat(obs): set 72h CloudWatch log retention","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/134"},"id":"PVTI_lAHOCf--fM4BKOL_zgkJCgA","labels":["enhancement","area/k8s","v1-mvp","area/observability","p2"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"feat(obs): set 72h CloudWatch log retention"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nHarden infra observability and SSM reliability using IaC (Terraform), while keeping gray areas manual for now.\n\n## Scope (Terraform)\n- CloudWatch alarms:\n  - CPUUtilization (control-plane + worker)\n  - CPUCreditBalance (control-plane + worker)\n  - CPUCreditUsage (optional)\n- VPC Flow Logs to CloudWatch with 72h retention.\n- VPC Interface Endpoints for SSM: `ssm`, `ec2messages`, `ssmmessages` (private subnets + SG).\n- Log groups + retention (72h) for flow logs and infra logs.\n\n## Manual for now (track as follow-up)\n- CloudWatch Agent install/config for RAM/logs on nodes (keep manual for now).\n- Instance reboot / SSM troubleshooting steps.\n\n## DoD\n- Alarms created and visible in CloudWatch.\n- Flow logs active for private subnet(s) with 72h retention.\n- SSM endpoints present and reachable from private subnets.\n- Minimal docs update explaining alarms + flow logs and manual steps.\n\n## Dependencies / Notes\n- Relates to SSM stability issues observed on 2026-01-23.\n- Keep costs minimal (short retention, limited alarms).\n","number":135,"repository":"ClementV78/CloudRadar","title":"feat(infra): harden observability + SSM reliability","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/135"},"id":"PVTI_lAHOCf--fM4BKOL_zgkKzcU","labels":["enhancement","area/infra","v1-mvp","area/observability","p2"],"milestone":{"description":"","dueOn":"","title":"v1-mvp"},"priority":"P2","repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"feat(infra): harden observability + SSM reliability"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nAdd a local pre-commit hook to lint GitHub Actions workflows (actionlint + yamllint) before commits.\n\n## Scope\n- Add pre-commit config to run actionlint and yamllint on `.github/workflows/*.yml`.\n- Document installation and usage.\n\n## DoD\n- `pre-commit run --all-files` lints GitHub Actions workflows.\n- Docs explain setup and how to run locally.\n\n## Notes\n- Keep yamllint aligned with existing repo rules (ignore line-length if already noisy).","number":138,"repository":"ClementV78/CloudRadar","title":"ci(tooling): add pre-commit hook for GitHub Actions workflows","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/138"},"id":"PVTI_lAHOCf--fM4BKOL_zgkLoIg","labels":["area/infra","kind/ci"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Ready","title":"ci(tooling): add pre-commit hook for GitHub Actions workflows"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nAllow temporary EC2 Serial Console login for the k3s server when SSM is offline.\n\n## Scope\n- Add optional cloud-init input to set a hashed password for ec2-user.\n- Document how to enable/disable it and replace the instance.\n\n## DoD\n- Cloud-init supports optional password hash for ec2-user.\n- Docs describe how to enable and roll back.\n- No plaintext secrets committed.\n\n## Dependencies\n- None","number":139,"repository":"ClementV78/CloudRadar","title":"fix(infra): temporary serial console access for k3s server","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/139"},"id":"PVTI_lAHOCf--fM4BKOL_zgkLq_Q","labels":["area/infra","kind/maintenance","v1-mvp"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/140","https://github.com/ClementV78/CloudRadar/pull/142"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"fix(infra): temporary serial console access for k3s server"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nPrevent SSM waiters from hanging and causing Pending/Delayed backlog in CI smoke checks.\n\n## Context\n`aws ssm wait command-executed` can hit MaxAttempts while commands remain Pending/InProgress. Long-running kubectl loops keep workers busy and block subsequent commands.\n\n## Scope\n- Replace `aws ssm wait` with a polling loop using `get-command-invocation` and a bounded timeout.\n- Add `--timeout-seconds` to `aws ssm send-command`.\n- Add `kubectl --request-timeout=5s` to SSM commands that run kubectl.\n- Update runbook notes if behavior changes.\n\n## DoD\n- CI no longer fails due to `aws ssm wait` MaxAttempts on Pending/InProgress.\n- Commands time out cleanly with clear logs.\n- Docs updated if needed.\n","number":145,"repository":"ClementV78/CloudRadar","title":"ci(infra): avoid SSM waiter hangs with polling and timeouts","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/145"},"id":"PVTI_lAHOCf--fM4BKOL_zgkL7-k","labels":["area/infra","v1-mvp","kind/ci"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/146"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"ci(infra): avoid SSM waiter hangs with polling and timeouts"},{"assignees":["ClementV78"],"content":{"body":"## Context\nDuring recent redeploys, the k3s server runs without swap and becomes unstable under ArgoCD + CSI load. We want a consistent 2GB swap across k3s nodes after every provision.\n\n## Scope\n- Add 2GB swap provisioning to k3s server/worker cloud-init (user-data).\n- Persist swap with /etc/fstab.\n- Ensure the swap setup is idempotent and safe to re-run.\n- Document the change in the infra docs/runbook (where k3s bootstrap is described).\n\n## DoD\n- [ ] k3s server/worker instances come up with 2GB swap active (validated via `swapon --show`).\n- [ ] Swap is persisted in `/etc/fstab` and survives reboots/redeploys.\n- [ ] Documentation updated with the swap setup and verification command.\n- [ ] Evidence posted in the issue (CLI output or workflow run).\n","number":147,"repository":"ClementV78/CloudRadar","title":"feat(infra): add 2GB swap on k3s nodes","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/147"},"id":"PVTI_lAHOCf--fM4BKOL_zgkMPIw","labels":["area/infra","kind/maintenance","p1"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/152"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"priority":"P1","repository":"https://github.com/ClementV78/CloudRadar","size":"S","status":"Done","title":"feat(infra): add 2GB swap on k3s nodes"},{"assignees":["ClementV78"],"content":{"body":"## Context\nOpenSky connections can fail for extended periods (IP blocked). The ingester currently retries every ~10s indefinitely, creating noisy logs and unnecessary load.\n\n## Scope\n- Add progressive backoff after consecutive OpenSky failures.\n- Disable ingestion after the final backoff tier until restart.\n\n## Dependencies\n- None.\n\n## DoD\n- [ ] Backoff tiers: 1s, 2s, 5s, 10s, 30s, 60s, 5m, 10m, 30m, 1h, then stop.\n- [ ] Logs indicate backoff tier and final disablement.\n","number":149,"repository":"ClementV78/CloudRadar","title":"fix(app): add backoff for OpenSky connection failures","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/149"},"id":"PVTI_lAHOCf--fM4BKOL_zgkNP6I","labels":["bug","area/app","kind/maintenance","v1.1","p2"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/146","https://github.com/ClementV78/CloudRadar/pull/151"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"fix(app): add backoff for OpenSky connection failures"},{"assignees":["ClementV78"],"content":{"body":"## Context\nIngester currently reads OpenSky secrets directly from SSM inside the code. This couples the app to AWS and bypasses GitOps-style secret injection.\n\n## Scope\n- Install External Secrets Operator (ESO) in the cluster.\n- Add SecretStore/ExternalSecret definitions for OpenSky credentials (and other SSM-backed secrets used by the app).\n- Update deployments to consume Kubernetes Secrets instead of SSM reads in code.\n- Remove SSM client usage from application code where applicable.\n\n## Dependencies\n- Requires AWS IAM permissions for ESO to read SSM.\n- Requires decisions on secret naming conventions and namespaces.\n\n## DoD\n- [ ] ESO installed and documented.\n- [ ] OpenSky secrets delivered via ExternalSecret.\n- [ ] App no longer reads SSM directly.\n- [ ] Docs updated (runbook/architecture).\n","number":150,"repository":"ClementV78/CloudRadar","title":"refactor(app): replace SSM reads with External Secrets","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/150"},"id":"PVTI_lAHOCf--fM4BKOL_zgkNpBs","labels":["enhancement","area/infra","area/app","v1.1","p2"],"milestone":{"description":"","dueOn":"","title":"v1.1"},"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"refactor(app): replace SSM reads with External Secrets"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nProvide a secure admin API to scale the ingester deployment (replicas) by calling the Kubernetes API. This enables UI-driven operations while keeping the token hidden from end users.\n\n## Scope\n- Admin API service (small HTTP server) with one endpoint: `POST /admin/ingester/scale` (replicas 0/1/2).\n- ServiceAccount + minimal RBAC: allow `patch` on `deployments/scale` for `ingester` only.\n- Internal token auth for the admin endpoint (Secret + env var).\n- Edge injects `X-Internal-Token` header when Basic Auth succeeds.\n- Allow direct admin curl from SSM by passing the internal token.\n- K8s manifests under `k8s/apps/admin-scale` (or similar).\n- Runbook update with flow diagram + curl examples.\n\n## DoD\n- [ ] Admin API can scale `ingester` replicas in `cloudradar` namespace.\n- [ ] RBAC is minimal and restricted to `deployments/scale` for `ingester`.\n- [ ] Internal token stored as a Kubernetes Secret and validated by the API.\n- [ ] Edge injects the internal token header on successful Basic Auth.\n- [ ] Docs/runbook updated with flow + usage examples.\n- [ ] Smoke test evidence recorded (kubectl/get deploy or curl).\n\n## Dependencies\n- k3s cluster available (#7).\n- Edge Nginx deployed (#8).\n\n## Notes\n- Keep the endpoint non-public; only reachable via edge or SSM network.\n","number":159,"repository":"ClementV78/CloudRadar","title":"feat(app): admin API to scale ingester via K8s","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/159"},"id":"PVTI_lAHOCf--fM4BKOL_zgkPoEk","labels":["area/k8s","area/app","v1.1"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/160"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"feat(app): admin API to scale ingester via K8s"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nEnsure the edge security group can reach the admin-scale NodePort (32737) on k3s nodes.\n\n## Scope\n- Add `edge_admin_nodeport` to the set of nodeport rules opened from edge -> k3s SG.\n- Keep existing nodeport filtering logic intact.\n\n## DoD\n- [ ] Terraform plan/apply shows an inbound SG rule for port 32737 from edge SG.\n- [ ] Edge can reach admin-scale NodePort without timeout.\n\n## Notes\n- This fixes the 504 timeout when calling /admin/ingester/scale via edge.\n","number":161,"repository":"ClementV78/CloudRadar","title":"fix(infra): allow edge access to admin nodeport","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/161"},"id":"PVTI_lAHOCf--fM4BKOL_zgkQhUI","labels":["area/infra","kind/maintenance","v1.1"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/162"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"fix(infra): allow edge access to admin nodeport"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nAllow admin API to scale ingester without ArgoCD self-healing reverting replicas to 0.\n\n## Scope\n- Add ignoreDifferences for `spec.replicas` on Deployment `ingester` in the ArgoCD Application manifest.\n- Keep auto-sync and self-heal for all other fields.\n\n## DoD\n- [ ] ArgoCD Application includes ignoreDifferences for ingester replicas.\n- [ ] Scaling ingester via admin API no longer auto-reverts to 0.\n\n## Notes\n- Application manifest is generated in `scripts/bootstrap-argocd.sh`.\n","number":163,"repository":"ClementV78/CloudRadar","title":"fix(ops): ignore ingester replicas in ArgoCD","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/163"},"id":"PVTI_lAHOCf--fM4BKOL_zgkQoOA","labels":["area/infra","kind/maintenance","v1.1"],"linked pull requests":["https://github.com/ClementV78/CloudRadar/pull/164"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Done","title":"fix(ops): ignore ingester replicas in ArgoCD"},{"assignees":["ClementV78"],"content":{"body":"## Goal\nPersist processor aggregates to SQLite so data survives env restarts/destroys (via S3 backups).\n\n## Scope\n- Add SQLite persistence layer for processor aggregates (last position, short tracks, counters).\n- Keep Redis as hot cache if needed (optional).\n- Update schema/migrations and data access layer.\n- Update docs/runbooks with persistence + restore notes.\n\n## DoD\n- Aggregates are stored in SQLite and survive pod restarts.\n- Backup/restore path documented (leveraging #117).\n\n## Dependencies\n- Depends on #117 (SQLite + PVC + S3 backups).\n- Depends on #5 (processor v1 aggregates).\n\n## Notes\n- Goal is durability; UI/API should be able to read from SQLite when Redis is cold.\n","number":165,"repository":"ClementV78/CloudRadar","title":"feat(app): persist processor aggregates to SQLite","type":"Issue","url":"https://github.com/ClementV78/CloudRadar/issues/165"},"id":"PVTI_lAHOCf--fM4BKOL_zgkQ9aA","labels":["area/app","v1.1"],"repository":"https://github.com/ClementV78/CloudRadar","status":"Backlog","title":"feat(app): persist processor aggregates to SQLite"}],"totalCount":77}
