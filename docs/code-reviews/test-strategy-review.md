# Code Review ‚Äî Proposition "Test Strategy v1.1" (Codex)

> Reviewer: GitHub Copilot  
> Date: 2026-02-23  
> Scope: Review de la proposition Codex pour introduire des tests d'int√©gration

---

## 1. √âtat des lieux actuel

Avant de reviewer la proposition, il faut mesurer le point de d√©part :

| Service | Langage | Source files | Tests | Type | Framework test |
|---|---|---|---|---|---|
| **dashboard** | Java/Spring Boot 3.3.5 | 29 | 4 (1024 LOC) | 1 `@WebMvcTest` slice + 3 unit Mockito | `spring-boot-starter-test` |
| **ingester** | Java/Spring Boot 3.3.5 | 13 | **0** | ‚Äî | **aucune d√©pendance test** |
| **processor** | Java/Spring Boot 3.3.5 | 8 | **0** | ‚Äî | **aucune d√©pendance test** |
| **admin-scale** | Python 3.11 | 1 | **0** | ‚Äî | ‚Äî |
| **health** | Python 3.11 | ~2 | **0** | ‚Äî | ‚Äî |
| **frontend** | React/TS | ~20 | **0** | ‚Äî | Vitest non configur√© |

**Tests CI actuels :**
- `build-and-push.yml` : build Docker matrix (6 services) ‚Üí **aucun `mvn test`**
- `ci-infra.yml` : smoke tests post-deploy (edge paths `/healthz`, `/grafana/`, `/prometheus/`) + ArgoCD sync check
- **Ratio actuel : 100% dashboard / 0% ailleurs**

```mermaid
block-beta
  columns 7
  header["Couverture de test par service"]:7
  space:7
  A["dashboard"] B["ingester"] C["processor"] D["frontend"] E["health"] F["admin-scale"] G["CI smoke"]
  A1["4 tests
1024 LOC"] B1["0 test"] C1["0 test"] D1["0 test"] E1["0 test"] F1["0 test"] G1["/healthz
/grafana
/prometheus"]

  style A1 fill:#4caf50,color:#fff
  style B1 fill:#f44336,color:#fff
  style C1 fill:#f44336,color:#fff
  style D1 fill:#f44336,color:#fff
  style E1 fill:#f44336,color:#fff
  style F1 fill:#f44336,color:#fff
  style G1 fill:#ff9800,color:#fff
```

### Diagnostic cl√©

Le probl√®me n'est pas un manque de tests d'int√©gration ‚Äî c'est un manque de tests tout court sur 5 des 6 services. La proposition Codex est bonne en structure mais **saute une √©tape critique** : il faut d'abord des fondations avant de penser int√©gration.

---

## 2. Review de la proposition Codex

### Niveau 1 : Context smoke tests ‚Äî ‚úÖ Bon, mais incomplet

> "1 test `@SpringBootTest` par service"

**Verdict : Excellent conseil, ROI maximal.**

Mais il manque un pr√©requis : ingester et processor n'ont m√™me pas `spring-boot-starter-test` dans leur `pom.xml`. Il faut d'abord :

1. Ajouter la d√©pendance test dans `pom.xml` de ingester et processor
2. Cr√©er le test `@SpringBootTest` qui charge le contexte
3. Exclure les beans qui n√©cessitent Redis/OpenSky (profil `test` ou `@MockBean`)

**Am√©lioration propos√©e :**

```java
// IngesterApplicationTests.java
@SpringBootTest
@ActiveProfiles("test")
class IngesterApplicationTests {
    @Test
    void contextLoads() {
        // catches DI wiring, missing beans, bad config
    }
}
```

Avec un `application-test.yml` minimal (scheduler disabled, Redis connection stubbed).  
Pas besoin de Testcontainers ici ‚Äî juste `@MockBean` sur les clients externes.

**Effort :** ~1h par service (ingester, processor).  
**Ce que √ßa attrape :** erreurs de c√¢blage DI, `@ConfigurationProperties` mal form√©es, constructeurs manquants ‚Äî les bugs les plus fr√©quents lors de refactoring.

---

### Niveau 2 : Contract integration tests ‚Äî ‚ö†Ô∏è Partiellement couvert, √† recentrer

> "Test int√©gration endpoint r√©el avec d√©pendances mock√©es/stub (Redis/HTTP externe)"

**Verdict : La direction est bonne, mais il faut pr√©ciser la cible.**

Le dashboard a d√©j√† un `@WebMvcTest(DashboardController.class)` avec `@MockBean` ‚Äî c'est un test slice, pas un contract test au sens strict (pas de v√©rification du sch√©ma JSON). Ce qui manque :

| Test manquant | Pourquoi c'est important |
|---|---|
| Ingester `OpenSkyClient` avec `MockWebServer` | V√©rifie le parsing de la r√©ponse OpenSky (JSON ‚Üí `FlightState`) |
| Dashboard SSE endpoint (`/api/flights/stream`) | V√©rifie le format SSE qu'attend le frontend |
| Dashboard `/api/flights` ‚Äî payload complet | V√©rifie la structure JSON finale (pas juste le status HTTP) |

**Ce que je ne recommanderais PAS :**
- ~~Contract testing (Pact/Spring Cloud Contract)~~ ‚Äî overkill pour un projet solo avec 1 consommateur frontend
- ~~Test de tous les endpoints~~ ‚Äî focus sur les 2-3 critiques

**Am√©lioration :** utiliser `MockWebServer` (OkHttp) pour l'ingester plut√¥t qu'un full mock Mockito du client HTTP. C'est plus r√©aliste et attrape les erreurs de s√©rialisation/d√©s√©rialisation.

```java
@SpringBootTest(webEnvironment = NONE)
class OpenSkyClientIntegrationTest {
    private MockWebServer server;

    @BeforeEach void setUp() { server = new MockWebServer(); server.start(); }
    @AfterEach void tearDown() throws Exception { server.shutdown(); }

    @Test
    void parsesOpenSkyResponse() {
        server.enqueue(new MockResponse()
            .setBody(loadFixture("opensky-response.json"))
            .setHeader("Content-Type", "application/json"));
        // configure client to point at server.url("/")
        // assert FlightState list is correctly parsed
    }
}
```

---

### Niveau 3 : Data-path integration tests ‚Äî ‚ö†Ô∏è Bon principe, mauvaise granularit√©

> "ingester ‚Üí Redis ‚Üí processor ‚Üí dashboard ‚Äî Testcontainers Redis"

**Verdict : Le principe est bon, l'impl√©mentation propos√©e est trop ambitieuse.**

Tester la cha√Æne compl√®te `ingester ‚Üí Redis ‚Üí processor ‚Üí dashboard` dans un seul test implique 4 services Spring Boot + un Redis ‚Äî c'est un test E2E d√©guis√©. **Trop lourd, trop fragile, trop lent.**

**Ce que je recommande √† la place :**

```mermaid
flowchart LR
  subgraph "‚ùå Proposition Codex (trop large)"
    direction LR
    I1[Ingester] -->|write| R1[(Redis)] -->|read| P1[Processor] -->|write| R1 -->|read| D1[Dashboard]
  end

  subgraph "‚úÖ Recommandation (3 tests cibl√©s)"
    direction TB
    subgraph T1 ["Test 1 : ingester ‚Üí Redis"]
      I2[Ingester] -->|write| R2[(TC Redis)]
    end
    subgraph T2 ["Test 2 : Redis ‚Üí processor"]
      R3[(TC Redis)] -->|read| P2[Processor]
    end
    subgraph T3 ["Test 3 : Redis ‚Üí dashboard"]
      R4[(TC Redis)] -->|read| D2[Dashboard]
    end
  end

  style R1 fill:#f44336,color:#fff
  style R2 fill:#4caf50,color:#fff
  style R3 fill:#4caf50,color:#fff
  style R4 fill:#4caf50,color:#fff
```

| Test | Scope | Ce qu'il valide |
|---|---|---|
| `RedisPublisherTest` (ingester) | ingester ‚Üí Redis | Les cl√©s Redis et le format de donn√©es publi√©s |
| `RedisAggregateProcessorTest` (processor) | Redis ‚Üí processor | Le processor lit correctement ce que l'ingester √©crit |
| `FlightQueryService` (dashboard) | Redis ‚Üí dashboard | Le dashboard reconstruit les DTOs depuis les cl√©s Redis |

Chaque test lance **un** Spring context + **un** Testcontainers Redis. Ils restent ind√©pendants mais valident les m√™mes cl√©s/structures Redis ‚Äî c'est un **contract test implicite par convention de cl√©s**.

**Effort :** ~2h par test, ~6h total.  
**Impact pipeline :** +30-45s par service (Redis container startup avec cache).  
**Pr√©requis :** `org.testcontainers:testcontainers` + `junit-jupiter` dans les poms.

---

### Niveau 4 : E2E smoke en environnement ‚Äî ‚úÖ D√©j√† bien parti, √† √©tendre

> "Apr√®s d√©ploiement : health checks + quelques requ√™tes API critiques"

**Verdict : Tu as d√©j√† la base, il manque les checks applicatifs.**

Existant (ci-infra smoke-tests) :
- ‚úÖ ArgoCD app sync + healthy
- ‚úÖ Edge path check : `/healthz` ‚Üí 200
- ‚úÖ Edge path check : `/grafana/` ‚Üí 200/301/302
- ‚úÖ Edge path check : `/prometheus/` ‚Üí 200/301/302

Manquant :
- ‚ùå `/api/flights` ‚Üí 200 + JSON array (prouve que le pipeline de donn√©es fonctionne)
- ‚ùå `/api/flights/count` ou √©quivalent ‚Üí nombre > 0 (prouve que Redis a des donn√©es)

**Am√©lioration :** ajouter 2 lignes dans le smoke test existant :

```bash
check_edge_path "/api/flights" 3
# + v√©rification que le body contient du JSON non-vide
```

**Effort :** ~30 min.  
**Ce que √ßa attrape :** d√©rive infra/config qui casse le data flow sans casser les health checks.

---

### Ratio 70/20/10 ‚Äî ‚ö†Ô∏è Cible correcte, mais priorisation √† revoir

Le ratio propos√© est standard et adapt√© au projet :

| Type | % cible | % actuel |
|---|---|---|
| Unit / slice | 70% | **100%** (mais uniquement dashboard) |
| Integration context/contract | 20% | **0%** |
| Pipeline / E2E smoke | 10% | **~5%** (edge path only) |

**Le probl√®me : le ratio s'applique au dashboard, pas au projet.**

Pour que le ratio ait du sens, il faut d'abord **√©tendre la couverture de base** aux 3 autres services Java. L'ordre de priorit√© devrait √™tre :

1. Foundation d'abord (Niveau 0 ‚Äî ajout√© ci-dessous)
2. Context smoke (Niveau 1)
3. Smoke E2E applicatifs (Niveau 4, quick win)
4. Data-path cibl√© (Niveau 3)
5. Contract integration (Niveau 2, si budget temps)

---

## 3. Proposition am√©lior√©e ‚Äî Plan incr√©mental

```mermaid
gantt
  title Roadmap d'impl√©mentation des tests
  dateFormat X
  axisFormat %s h
  todayMarker off

  section Phase 0 ‚Äî Fondations
    spring-boot-starter-test (pom.xml)   :a1, 0, 1
    application-test.yml                 :a2, after a1, 3
    mvn test dans CI                     :a3, after a1, 2
    Vitest frontend                      :a4, after a1, 3
    pytest health                        :a5, after a1, 2

  section Phase 1 ‚Äî Context Smoke
    contextLoads √ó 3 services            :b1, after a5, 4
    App.test.tsx + test_healthz.py       :b2, after a5, 2

  section Phase 2 ‚Äî Data-path
    Testcontainers Redis √ó 3             :c1, after b1, 12
    Redis keys documentation             :c2, after b1, 2

  section Phase 3 ‚Äî Contract + Frontend
    MockWebServer OpenSky                :d1, after c1, 4
    Dashboard API contract               :d2, after c1, 3
    Smoke CI /api/flights                :d3, after c1, 1
    Frontend Vitest components           :d4, after c1, 4

  section Phase 4 ‚Äî Excellence
    k6 performance baseline              :e1, after d1, 4
    Rollback validation                  :e2, after d1, 2
```

### Phase 0 : Fondations (pr√©requis, ~2h)

| T√¢che | Service | Effort |
|---|---|---|
| Ajouter `spring-boot-starter-test` au `pom.xml` | ingester, processor | 10 min |
| Cr√©er `application-test.yml` (scheduler off, Redis mock) | ingester, processor | 30 min |
| Configurer `mvn test` dans `build-and-push.yml` | CI | 20 min |
| Ajouter Vitest dans le frontend (`package.json`) | frontend | 30 min |
| Ajouter pytest pour health | health | 20 min |

> **Impact CI :** Le `build-and-push` devrait ex√©cuter `mvn verify -DskipITs` (unit/slice only) ou l'√©quivalent `npm test` pour le frontend. Aujourd'hui il ne lance **aucun test** ‚Äî c'est le trou le plus critique.

### Phase 1 : Context smoke ‚Äî chaque service d√©marre (~2h)

| Test | Service | Attrape |
|---|---|---|
| `IngesterApplicationTests.contextLoads()` | ingester | DI wiring, config |
| `ProcessorApplicationTests.contextLoads()` | processor | DI wiring, config |
| `DashboardApplicationTests.contextLoads()` | dashboard | (manque aussi !) |
| `App.test.tsx` (render sans crash) | frontend | Import errors, build |
| `test_healthz.py` | health | Endpoint 200, JSON format |

### Phase 2 : Data-path cibl√© avec Testcontainers (~6h)

| Test | Service | Validate |
|---|---|---|
| `RedisPublisherIntegrationTest` | ingester | Cl√©s Redis √©crites, format hash |
| `RedisAggregateProcessorIntegrationTest` | processor | Lecture et agr√©gation Redis |
| `FlightQueryServiceIntegrationTest` | dashboard | Reconstruction DTOs depuis Redis |

> **Convention de cl√©s Redis** : documenter dans un fichier partag√© (`docs/events-schemas/redis-keys.md`) pour que les tests restent align√©s entre services.

### Phase 3 : Contract HTTP + smoke E2E √©tendu (~3h)

| Test | Service | Validate |
|---|---|---|
| `OpenSkyClientIntegrationTest` (MockWebServer) | ingester | Parsing JSON OpenSky |
| `DashboardApiContractTest` (payload JSON) | dashboard | Structure JSON `/api/flights` |
| Smoke test CI : `check_edge_path "/api/flights"` | ci-infra | Data flow end-to-end |

### Phase 4 : Frontend minimal (~2h)

| Test | Service | Validate |
|---|---|---|
| `FlightMap.test.tsx` (render, mock data) | frontend | Composant principal s'affiche |
| `DetailPanel.test.tsx` (render) | frontend | Panel d√©tail avion |

---

## 4. Points d'attention

### 4.1 Co√ªt CI

| Ajout | Impact pipeline |
|---|---|
| `mvn test` dans build-and-push | +20-30s par service |
| Testcontainers Redis | +30-45s par service (premi√®re run, cached ensuite) |
| Vitest frontend | +5-10s |
| pytest health | +2-3s |

Total estim√© : **+2-3 min** sur le pipeline build. C'est acceptable si les tests sont en matrice (parall√©lis√©s par service, d√©j√† le cas dans `build-and-push.yml`).

### 4.2 Testcontainers : attention au CI runner

GitHub Actions Ubuntu runners ont Docker, donc Testcontainers fonctionne nativement. Pas de config sp√©ciale requise.

### 4.3 Ce que je ne recommande PAS (√† ce stade)

| Outil/Approche | Pourquoi non |
|---|---|
| Pact / Spring Cloud Contract | Un seul consommateur (frontend), overkill |
| JaCoCo coverage gates | Ajouter d'abord les tests, la couverture viendra |
| Mutation testing (PIT) | Pertinent plus tard, pas maintenant |
| Test E2E frontend (Cypress/Playwright) | Trop lourd pour le MVP, les smoke CI suffisent |
| Test d'injection de fautes (Chaos) | Pr√©matur√© sans HA ni multi-node |

### 4.4 Profil `test` Spring ‚Äî strat√©gie

Pour les tests de Phase 1, cr√©er un `application-test.yml` par service :

```yaml
# src/ingester/src/test/resources/application-test.yml
spring:
  main:
    allow-bean-definition-overriding: true
app:
  opensky:
    enabled: false
  scheduler:
    enabled: false
  redis:
    host: localhost
    port: 6379  # stubbed by @MockBean or Testcontainers
```

Cela permet aux `@SpringBootTest` de charger le contexte sans d√©pendances externes r√©elles.

---

## 5. Cat√©gories de tests manquantes ‚Äî vers l'excellence DevOps

La strat√©gie Codex + les am√©liorations des sections 2-4 couvrent la **pyramide de tests applicatifs** (unit ‚Üí int√©gration ‚Üí E2E). Mais une strat√©gie de test DevOps compl√®te d√©passe le code applicatif. Voici les cat√©gories **non couvertes** qui s√©parent un "bon" d'un "excellent" pipeline, sans tomber dans l'overkill.

### 5.1 Cartographie compl√®te ‚Äî ce qui existe vs ce qui manque

| Cat√©gorie | Sous-type | Statut | O√π | Effort |
|---|---|---|---|---|
| **Unit tests** | Logique m√©tier (Mockito) | ‚úÖ dashboard only | `src/dashboard/test/` | ‚Äî |
| **Slice tests** | `@WebMvcTest` (controller layer) | ‚úÖ dashboard only | `src/dashboard/test/` | ‚Äî |
| **Context smoke** | `@SpringBootTest` | ‚ùå Absent | ‚Äî | ~1h |
| **Integration** (data-path) | Testcontainers Redis | ‚ùå Absent | ‚Äî | ~6h |
| **Contract HTTP** | MockWebServer / payload JSON | ‚ùå Absent | ‚Äî | ~3h |
| **E2E smoke** (infra) | Edge path checks | ‚úÖ Partiel | `ci-infra.yml` | ~30min pour √©tendre |
| **Static analysis ‚Äî IaC** | tfsec (Terraform) | ‚úÖ | `ci-infra.yml` | ‚Äî |
| **Static analysis ‚Äî Java** | Checkstyle / SpotBugs | ‚ùå Absent | ‚Äî | ~1h |
| **Static analysis ‚Äî Frontend** | ESLint + Prettier | ‚ùå Absent | ‚Äî | ~30min |
| **Static analysis ‚Äî Dockerfile** | Hadolint | ‚ùå Absent | ‚Äî | ~10min |
| **K8s manifest validation** | kubeconform | ‚ùå Absent | ‚Äî | ~30min |
| **Dependency vulnerability scan** | Dependabot / Trivy fs | ‚ùå Absent | ‚Äî | ~30min |
| **Container image scan** | Trivy image | ‚ùå Absent | ‚Äî | ~15min |
| **Secret scanning** | GitGuardian (GitHub App) | ‚úÖ | GitHub App | ‚Äî |
| **Performance baseline** | k6 / Artillery | ‚ùå Absent | ‚Äî | ~2h |
| **Config drift detection** | ArgoCD sync status | ‚úÖ | `ci-infra.yml` | ‚Äî |
| **Rollback validation** | Post-rollback health check | ‚ùå Absent | ‚Äî | ~1h |

### 5.2 Static Analysis (SAST / Linting) ‚Äî **priorit√© haute**

La cat√©gorie enti√®re est absente c√¥t√© applicatif. C'est le type de test le plus rentable : **0 faux n√©gatif, pas de maintenance, ex√©cution en secondes.**

#### Java ‚Äî Checkstyle + SpotBugs

```yaml
# dans build-and-push.yml, etape avant mvn test
- name: Static analysis (Java)
  run: mvn checkstyle:check spotbugs:check -pl ${{ matrix.service }}
```

| Outil | Ce qu'il attrape | Config |
|---|---|---|
| **Checkstyle** | Style, naming, imports inutilis√©s, javadoc | `google_checks.xml` (standard) |
| **SpotBugs** | Null-pointer potentiels, concurrency bugs, perf anti-patterns | Plugin Maven, zero config |

**Effort** : ~1h (ajout plugins Maven + suppressions initiales).  
**Impact CI** : +5-10s par service.

#### Frontend ‚Äî ESLint + Prettier

```yaml
- name: Lint frontend
  working-directory: src/frontend
  run: npx eslint src/ --max-warnings 0 && npx prettier --check src/
```

**Effort** : ~30 min (init config + fix warnings existants).  
**Impact CI** : +3-5s.

#### Dockerfile ‚Äî Hadolint

D√©j√† recommand√© dans [ci-workflows-review.md](ci-workflows-review.md) section 8.4.

```yaml
- name: Lint Dockerfile
  uses: hadolint/hadolint-action@v3.1.0
  with:
    dockerfile: src/${{ matrix.service }}/Dockerfile
```

**Effort** : ~10 min.

### 5.3 Kubernetes Manifest Validation ‚Äî **priorit√© haute**

Tu as **69 manifests YAML** et **aucune validation de sch√©ma**. `ci-k8s.yml` v√©rifie la coh√©rence des versions et la casse GHCR, mais ne valide pas que les manifests sont des objets Kubernetes corrects.

```yaml
# dans ci-k8s.yml
validate-manifests:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4
    - name: Install kubeconform
      run: |
        curl -sSL https://github.com/yannh/kubeconform/releases/latest/download/kubeconform-linux-amd64.tar.gz \
          | tar xz -C /usr/local/bin
    - name: Validate k8s manifests
      run: |
        kubeconform -strict -summary \
          -schema-location default \
          -schema-location 'https://raw.githubusercontent.com/datreeio/CRDs-catalog/main/{{.Group}}/{{.ResourceKind}}_{{.ResourceVersion}}.json' \
          k8s/
```

| Outil | Avantage | Alternative |
|---|---|---|
| **kubeconform** | Rapide, supporte CRDs (ArgoCD, Prometheus), maintenu | `kubeval` (abandonn√©) |

**Ce que √ßa attrape** : champs mal nomm√©s, apiVersion obsol√®tes, CRDs mal form√©s (ServiceMonitor, Application ArgoCD).  
**Effort** : ~30 min.  
**Impact CI** : +3-5s.  
**Pertinence DevOps** : ‚≠ê‚≠ê‚≠ê ‚Äî en entretien, pouvoir dire "je valide mes manifests k8s en CI avec kubeconform et support CRDs" est un signal fort.

### 5.4 Dependency Vulnerability Scanning (SCA) ‚Äî **priorit√© haute**

Pas de Dependabot configur√©, pas de `trivy fs`. Les d√©pendances (Spring Boot, Redis client, Jackson) ne sont pas scann√©es pour des CVEs connues.

Deux options compl√©mentaires :

#### Option A ‚Äî Dependabot (passif, PR automatiques)

```yaml
# .github/dependabot.yml
version: 2
updates:
  - package-ecosystem: "maven"
    directory: "/src/ingester"
    schedule: { interval: "weekly" }
  - package-ecosystem: "maven"
    directory: "/src/processor"
    schedule: { interval: "weekly" }
  - package-ecosystem: "maven"
    directory: "/src/dashboard"
    schedule: { interval: "weekly" }
  - package-ecosystem: "npm"
    directory: "/src/frontend"
    schedule: { interval: "weekly" }
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule: { interval: "weekly" }
```

#### Option B ‚Äî Trivy filesystem scan (actif, bloquant en CI)

```yaml
# dans build-and-push.yml
- name: Scan dependencies for CVEs
  uses: aquasecurity/trivy-action@master
  with:
    scan-type: fs
    scan-ref: src/${{ matrix.service }}
    severity: CRITICAL,HIGH
    exit-code: 1
```

**Recommandation** : les deux. Dependabot pour les mises √† jour proactives, Trivy pour le gate CI.  
**Effort** : ~30 min total.

### 5.5 Container Image Scanning ‚Äî **priorit√© moyenne**

Les images Docker sont pouss√©es sur GHCR sans scan de vuln√©rabilit√©s. Un `trivy image` post-build d√©tecte les CVEs dans les couches OS et les d√©pendances runtime.

```yaml
# dans build-and-push.yml, apr√®s docker push
- name: Scan container image
  uses: aquasecurity/trivy-action@master
  with:
    image-ref: ${{ steps.meta.outputs.tags }}
    severity: CRITICAL,HIGH
    exit-code: 0  # warning only, pas bloquant au d√©but
```

**Effort** : ~15 min.  
**Impact CI** : +20-30s (pull + scan).

### 5.6 Performance Baseline Testing ‚Äî **priorit√© basse, haut impact entretien**

Aucun test de performance n'existe. Pour un portfolio DevOps, m√™me un test minimaliste d√©montre la comp√©tence.

**Recommandation : k6** (open-source Grafana Labs, int√©gration native Prometheus/Grafana).

```javascript
// tests/perf/baseline.js
import http from 'k6/http';
import { check } from 'k6';

export const options = {
  vus: 10,               // 10 utilisateurs virtuels
  duration: '30s',
  thresholds: {
    http_req_duration: ['p95<500'],  // 95th percentile < 500ms
    http_req_failed: ['rate<0.01'],   // < 1% erreurs
  },
};

export default function () {
  const res = http.get('https://EDGE_IP/api/flights');
  check(res, {
    'status is 200': (r) => r.status === 200,
    'body is JSON array': (r) => JSON.parse(r.body).length >= 0,
  });
}
```

**Pas dans le CI standard** ‚Äî √† ex√©cuter manuellement ou en workflow_dispatch post-deploy.  
**Effort** : ~2h (script + workflow optionnel).  
**Pertinence entretien** : pouvoir dire "j'ai un baseline k6 √† 10 VUs avec des thresholds p95 < 500ms, int√©gr√© √† Grafana" = signal fort SRE/Platform Engineering.

### 5.7 Rollback Validation ‚Äî **priorit√© basse**

Le pipeline d√©ploie mais ne v√©rifie pas que le syst√®me survit √† un rollback. Dans un contexte GitOps ArgoCD, un test minimal :

```bash
# Post-deploy, v√©rifier que la version pr√©c√©dente peut √™tre restaur√©e
argocd app rollback cloudradar 0  # rollback to previous sync
# re-check /healthz et /api/flights
sleep 30
check_edge_path "/healthz" 3
check_edge_path "/api/flights" 3
# re-sync to latest
argocd app sync cloudradar
```

Pas indispensable au MVP, mais pertinent en entretien pour d√©montrer une maturit√© op√©rationnelle.

### 5.8 Vision compl√®te ‚Äî Test Taxonomy DevOps

```mermaid
block-beta
  columns 1

  P["üèîÔ∏è Performance ‚Äî k6 baseline (10 VUs, p95 < 500ms)"]
  E["üåê E2E Smoke ‚Äî CI post-deploy (/healthz, /api/flights)"]
  D["üîó Data-path Integration ‚Äî Testcontainers Redis (ingester ‚Üî Redis ‚Üî processor)"]
  C["üìù Contract HTTP ‚Äî MockWebServer, payload JSON"]
  S["üöÄ Context Smoke ‚Äî @SpringBootTest contextLoads()"]
  U["üß™ Unit / Slice ‚Äî Mockito, @WebMvcTest"]
  SA["üîç Static Analysis ‚Äî Checkstyle ¬∑ SpotBugs ¬∑ ESLint ¬∑ Hadolint ¬∑ tfsec ¬∑ kubeconform"]
  SC["üõ°Ô∏è Supply Chain Security ‚Äî Dependabot ¬∑ Trivy fs ¬∑ Trivy image ¬∑ GitGuardian"]

  style P fill:#e1bee7,color:#000
  style E fill:#ce93d8,color:#000
  style D fill:#ba68c8,color:#fff
  style C fill:#ab47bc,color:#fff
  style S fill:#9c27b0,color:#fff
  style U fill:#7b1fa2,color:#fff
  style SA fill:#37474f,color:#fff
  style SC fill:#263238,color:#fff
```

> Lecture : la pyramide se lit de bas en haut. Les couches basses (unit) sont nombreuses et rapides. Les couches hautes (perf, E2E) sont rares et lentes. Les deux couches transversales (static analysis + supply chain) s'ex√©cutent en parall√®le √† chaque PR.

### 5.9 O√π chaque test s'ex√©cute dans le pipeline CI

```mermaid
flowchart LR
  subgraph PR["Pull Request"]
    direction TB
    L["üîç Lint & Static Analysis\nCheckstyle ¬∑ SpotBugs\nESLint ¬∑ Hadolint\ntfsec ¬∑ kubeconform"]
    UT["üß™ Unit & Slice Tests\nmvn test ¬∑ npm test\npytest"]
    SCA["üõ°Ô∏è Supply Chain\nTrivy fs ¬∑ Dependabot"]
    L --> UT --> SCA
  end

  subgraph Build["Merge ‚Üí Build"]
    direction TB
    B["üê≥ Docker Build\nMatrix 6 services"]
    IS["üîé Image Scan\nTrivy image"]
    B --> IS
  end

  subgraph Deploy["Deploy (dev)"]
    direction TB
    TF["üèóÔ∏è Terraform\nplan ‚Üí apply"]
    AG["‚ò∏Ô∏è ArgoCD Sync\nwait healthy"]
    SM["üåê Smoke Tests\n/healthz ¬∑ /api/flights\n/grafana ¬∑ /prometheus"]
    TF --> AG --> SM
  end

  subgraph Optional["On-Demand"]
    direction TB
    TC["üîó Integration\nTestcontainers Redis"]
    K6["üèîÔ∏è Performance\nk6 baseline"]
    RB["üîÑ Rollback\nvalidation"]
  end

  PR --> Build --> Deploy
  Deploy -.-> Optional

  style PR fill:#e3f2fd,color:#000
  style Build fill:#fff3e0,color:#000
  style Deploy fill:#e8f5e9,color:#000
  style Optional fill:#fce4ec,color:#000
```

### 5.10 R√©capitulatif ‚Äî Ordre d'impl√©mentation complet

| Rang | Cat√©gorie | Effort | ROI | Phase |
|---|---|---|---|---|
| 1 | `mvn test` / `npm test` dans CI | 20 min | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Phase 0 |
| 2 | Hadolint Dockerfile | 10 min | ‚≠ê‚≠ê‚≠ê‚≠ê | Phase 0 |
| 3 | kubeconform k8s manifests | 30 min | ‚≠ê‚≠ê‚≠ê‚≠ê | Phase 0 |
| 4 | Dependabot config | 15 min | ‚≠ê‚≠ê‚≠ê‚≠ê | Phase 0 |
| 5 | `@SpringBootTest.contextLoads()` √ó 3 | 2h | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Phase 1 |
| 6 | ESLint + Prettier frontend | 30 min | ‚≠ê‚≠ê‚≠ê | Phase 1 |
| 7 | Checkstyle + SpotBugs Java | 1h | ‚≠ê‚≠ê‚≠ê | Phase 1 |
| 8 | Trivy fs (dependency CVEs) | 15 min | ‚≠ê‚≠ê‚≠ê‚≠ê | Phase 1 |
| 9 | Smoke E2E `/api/flights` | 30 min | ‚≠ê‚≠ê‚≠ê‚≠ê | Phase 1 |
| 10 | Trivy image (container CVEs) | 15 min | ‚≠ê‚≠ê‚≠ê | Phase 2 |
| 11 | Testcontainers Redis √ó 3 | 6h | ‚≠ê‚≠ê‚≠ê | Phase 2 |
| 12 | Contract HTTP (MockWebServer) | 3h | ‚≠ê‚≠ê‚≠ê | Phase 3 |
| 13 | Frontend Vitest | 2h | ‚≠ê‚≠ê | Phase 3 |
| 14 | k6 performance baseline | 2h | ‚≠ê‚≠ê (‚≠ê‚≠ê‚≠ê‚≠ê pour entretien) | Phase 4 |
| 15 | Rollback validation | 1h | ‚≠ê‚≠ê | Phase 4 |

**Total : ~20h** (vs 15h pr√©c√©demment) pour passer de "tests dashboard uniquement" √† "strat√©gie de test DevOps compl√®te".

---

## 6. Vue par type de test

La section 3 organise le travail par **phase d'impl√©mentation** (quand). Cette section organise le m√™me p√©rim√®tre par **type de test** (quoi), avec pour chacun : d√©finition, outils, services concern√©s, et phase d'impl√©mentation.

```mermaid
mindmap
  root((Test Strategy<br/>CloudRadar))
    üß™ Unitaire
      Mockito
      @WebMvcTest
      pytest
      Vitest
    üîó Int√©gration
      @SpringBootTest
      Testcontainers Redis
      MockWebServer
    üåê E2E / Smoke
      CI post-deploy
      /healthz /api/flights
      Rollback validation
    üîí S√©curit√©
      tfsec IaC
      Trivy fs/image
      Dependabot
      GitGuardian
    üìè Qualit√© de code
      Checkstyle
      SpotBugs
      ESLint + Prettier
      Hadolint
    ‚öôÔ∏è Validation infra
      kubeconform
      terraform validate
      ArgoCD sync
    üèîÔ∏è Performance
      k6 baseline
    üñ•Ô∏è Interface
      Vitest render
      Component smoke
```

---

### 6.1 Tests Unitaires

> **Objectif** : valider la logique m√©tier isol√©e, sans d√©pendances externes.

| Quoi | Service | Outil | Phase | Effort |
|---|---|---|---|---|
| Logique m√©tier (mocking) | dashboard | Mockito + JUnit 5 | ‚úÖ Existant | ‚Äî |
| `QueryParser` string parsing | dashboard | JUnit 5 (pur) | ‚úÖ Existant | ‚Äî |
| `PlanespottersPhotoService` cache logic | dashboard | Mockito | ‚úÖ Existant | ‚Äî |
| `FlightState` mapping / DTO | ingester | JUnit 5 | Phase 1 | 30 min |
| `PositionEvent` / aggregation logic | processor | JUnit 5 | Phase 1 | 30 min |
| `test_healthz.py` endpoint logic | health | pytest | Phase 0 | 20 min |
| Composant React render | frontend | Vitest + Testing Library | Phase 4 | 2h |

**Pr√©requis** : `spring-boot-starter-test` dans les pom.xml (Phase 0).

**Ratio cible** : 70% du volume total de tests.

---

### 6.2 Tests d'Int√©gration

> **Objectif** : valider les interactions entre composants (DI wiring, Redis, HTTP externe).

```mermaid
flowchart TB
  subgraph CTX["Context Smoke (Phase 1)"]
    CS1["@SpringBootTest<br/>contextLoads()<br/>ingester"]
    CS2["@SpringBootTest<br/>contextLoads()<br/>processor"]
    CS3["@SpringBootTest<br/>contextLoads()<br/>dashboard"]
  end

  subgraph DP["Data-path (Phase 2)"]
    DP1["ingester ‚Üí Redis<br/>Testcontainers"]
    DP2["Redis ‚Üí processor<br/>Testcontainers"]
    DP3["Redis ‚Üí dashboard<br/>Testcontainers"]
  end

  subgraph CT["Contract HTTP (Phase 3)"]
    CT1["OpenSkyClient<br/>MockWebServer"]
    CT2["/api/flights<br/>payload JSON"]
  end

  CTX --> DP --> CT

  style CTX fill:#c8e6c9,color:#000
  style DP fill:#bbdefb,color:#000
  style CT fill:#ffe0b2,color:#000
```

| Sous-type | Service | Outil | Phase | Effort |
|---|---|---|---|---|
| **Context smoke** ‚Äî DI wiring, config | ingester | `@SpringBootTest` + `@ActiveProfiles("test")` | Phase 1 | 1h |
| **Context smoke** ‚Äî DI wiring, config | processor | `@SpringBootTest` + `@ActiveProfiles("test")` | Phase 1 | 1h |
| **Context smoke** ‚Äî DI wiring, config | dashboard | `@SpringBootTest` | Phase 1 | 30 min |
| **Data-path** ‚Äî cl√©s Redis √©crites | ingester | Testcontainers Redis | Phase 2 | 2h |
| **Data-path** ‚Äî agr√©gation Redis | processor | Testcontainers Redis | Phase 2 | 2h |
| **Data-path** ‚Äî DTOs depuis Redis | dashboard | Testcontainers Redis | Phase 2 | 2h |
| **Contract HTTP** ‚Äî parsing OpenSky JSON | ingester | MockWebServer (OkHttp) | Phase 3 | 2h |
| **Contract HTTP** ‚Äî payload `/api/flights` | dashboard | `@WebMvcTest` + assertions JSON | Phase 3 | 1h |

**Pr√©requis** : Testcontainers n√©cessite Docker sur le runner CI (GitHub Actions Ubuntu = OK).

**Ratio cible** : 20% du volume total de tests.

---

### 6.3 Tests E2E / Smoke

> **Objectif** : valider que le syst√®me d√©ploy√© fonctionne de bout en bout.

| Quoi | Scope | Outil | Phase | Effort |
|---|---|---|---|---|
| Edge `/healthz` ‚Üí 200 | Infra + app | curl via SSM | ‚úÖ Existant | ‚Äî |
| Edge `/grafana/` ‚Üí 200/301 | Infra + monitoring | curl via SSM | ‚úÖ Existant | ‚Äî |
| Edge `/prometheus/` ‚Üí 200/301 | Infra + monitoring | curl via SSM | ‚úÖ Existant | ‚Äî |
| ArgoCD sync + healthy | GitOps | kubectl via SSM | ‚úÖ Existant | ‚Äî |
| **`/api/flights` ‚Üí 200 + JSON array** | **Data pipeline** | curl via SSM | **Phase 1** | **30 min** |
| **Rollback ‚Üí re-check health** | **R√©silience** | argocd CLI via SSM | **Phase 4** | **1h** |

**Impact CI** : aucun (s'int√®gre dans le job `smoke-tests` existant de `ci-infra.yml`).

**Ratio cible** : 10% du volume total de tests.

---

### 6.4 Tests de S√©curit√©

> **Objectif** : d√©tecter les vuln√©rabilit√©s dans le code, les d√©pendances, les images et les secrets.

```mermaid
flowchart LR
  subgraph Existant
    TF["tfsec<br/>IaC security"]
    GG["GitGuardian<br/>Secret scanning"]
  end

  subgraph "√Ä ajouter"
    DEP["Dependabot<br/>Dependency updates"]
    TFS["Trivy fs<br/>CVE scan d√©pendances"]
    TI["Trivy image<br/>CVE scan containers"]
  end

  style Existant fill:#c8e6c9,color:#000
  style √Ä ajouter fill:#ffcdd2,color:#000
```

| Sous-type | Scope | Outil | Phase | Effort |
|---|---|---|---|---|
| **IaC security scan** | Terraform | tfsec | ‚úÖ Existant | ‚Äî |
| **Secret scanning** | Tous les repos | GitGuardian (GitHub App) | ‚úÖ Existant | ‚Äî |
| **Dependency CVEs** (passive) | Maven + npm + Actions | Dependabot `.github/dependabot.yml` | Phase 0 | 15 min |
| **Dependency CVEs** (active, CI gate) | `src/*/` | Trivy fs (CRITICAL,HIGH) | Phase 1 | 15 min |
| **Container image CVEs** | Images GHCR post-build | Trivy image (warning only) | Phase 2 | 15 min |

**Note** : les tests de s√©curit√© ne comptent pas dans le ratio 70/20/10 ‚Äî ils sont **transversaux** et s'ex√©cutent en parall√®le.

---

### 6.5 Tests de Qualit√© de Code (Static Analysis)

> **Objectif** : d√©tecter les anti-patterns, le code mort, les erreurs de style avant qu'ils n'atteignent le runtime.

| Sous-type | Langage | Outil | Phase | Effort |
|---|---|---|---|---|
| Style + conventions | Java | Checkstyle (`google_checks.xml`) | Phase 1 | 30 min |
| Bugs potentiels + null safety | Java | SpotBugs (plugin Maven) | Phase 1 | 30 min |
| Lint + best practices | TypeScript/React | ESLint | Phase 1 | 20 min |
| Format coh√©rent | TypeScript/React | Prettier | Phase 1 | 10 min |
| Dockerfile best practices | Docker | Hadolint | Phase 0 | 10 min |
| **IaC format** | Terraform | `terraform fmt` | ‚úÖ Existant | ‚Äî |

**Impact CI** : +10-15s total (tous les linters en parall√®le dans la matrice).

---

### 6.6 Tests de Validation d'Infrastructure

> **Objectif** : valider que les manifests IaC et k8s sont syntaxiquement corrects et conformes aux sch√©mas.

| Quoi | Scope | Outil | Phase | Effort |
|---|---|---|---|---|
| Terraform format | `infra/` | `terraform fmt -check` | ‚úÖ Existant | ‚Äî |
| Terraform validation | `infra/` | `terraform validate` | ‚úÖ Existant | ‚Äî |
| Terraform plan (dry-run) | `infra/` | `terraform plan` | ‚úÖ Existant | ‚Äî |
| Version sync images | `k8s/` | `check-app-version-sync.sh` | ‚úÖ Existant | ‚Äî |
| GHCR lowercase check | `k8s/` | `ci-k8s.yml` regex | ‚úÖ Existant | ‚Äî |
| **K8s schema validation** | **`k8s/` (69 manifests)** | **kubeconform + CRDs** | **Phase 0** | **30 min** |

**Note** : c'est le type le plus mature du projet. Il ne manque que kubeconform pour compl√©ter.

---

### 6.7 Tests de Performance

> **Objectif** : √©tablir une baseline mesurable pour d√©tecter les r√©gressions de latence.

| Quoi | Cible | Outil | Phase | Effort |
|---|---|---|---|---|
| Baseline API `/api/flights` | Dashboard | k6 (10 VUs, 30s, p95 < 500ms) | Phase 4 | 2h |

**Ex√©cution** : `workflow_dispatch` uniquement (pas dans le CI standard). R√©sultats int√©grables √† Grafana via Prometheus remote write.

**Pertinence** : priorit√© basse pour le fonctionnel, mais **tr√®s haute pour les entretiens** ‚Äî "j'ai un baseline k6 avec des thresholds SLO" est un signal SRE fort.

---

### 6.8 Tests d'Interface

> **Objectif** : valider que les composants frontend s'affichent correctement avec des donn√©es simul√©es.

| Quoi | Composant | Outil | Phase | Effort |
|---|---|---|---|---|
| Render smoke (le composant monte) | `App.tsx` | Vitest + React Testing Library | Phase 4 | 30 min |
| Carte Leaflet avec donn√©es mock | `FlightMap.tsx` | Vitest + Testing Library | Phase 4 | 1h |
| Panel d√©tail avion | `DetailPanel.tsx` | Vitest + Testing Library | Phase 4 | 30 min |

**Ce qu'on ne fait PAS** (√† ce stade) :
- ~~Cypress / Playwright~~ (E2E navigateur) ‚Äî trop lourd pour un MVP
- ~~Visual regression testing~~ (Percy, Chromatic) ‚Äî pertinent pour un design system, pas ici

---

### 6.9 Matrice crois√©e : Types √ó Phases

```mermaid
quadrantChart
  title Effort vs Impact par type de test
  x-axis "Faible effort" --> "Effort √©lev√©"
  y-axis "Faible impact" --> "Impact √©lev√©"

  "Qualit√© de code": [0.15, 0.60]
  "Validation infra": [0.20, 0.70]
  "S√©curit√© (Dependabot)": [0.10, 0.75]
  "Unitaires (Java)": [0.25, 0.80]
  "Context smoke": [0.30, 0.85]
  "E2E smoke /api": [0.15, 0.80]
  "S√©curit√© (Trivy)": [0.20, 0.65]
  "Int√©gration Redis": [0.65, 0.70]
  "Contract HTTP": [0.55, 0.55]
  "Interface (Vitest)": [0.50, 0.40]
  "Performance (k6)": [0.50, 0.50]
  "Rollback": [0.35, 0.35]
```

**Matrice compl√®te :**

| Type de test | Phase 0 | Phase 1 | Phase 2 | Phase 3 | Phase 4 |
|---|---|---|---|---|---|
| üß™ **Unitaire** | pytest health | JUnit ingester/processor | ‚Äî | ‚Äî | Vitest frontend |
| üîó **Int√©gration** | ‚Äî | contextLoads() √ó 3 | Testcontainers Redis √ó 3 | MockWebServer + contract JSON | ‚Äî |
| üåê **E2E / Smoke** | ‚Äî | `/api/flights` dans CI smoke | ‚Äî | ‚Äî | Rollback validation |
| üîí **S√©curit√©** | Dependabot config | Trivy fs | Trivy image | ‚Äî | ‚Äî |
| üìè **Qualit√© de code** | Hadolint | Checkstyle + SpotBugs + ESLint | ‚Äî | ‚Äî | ‚Äî |
| ‚öôÔ∏è **Validation infra** | kubeconform | ‚Äî | ‚Äî | ‚Äî | ‚Äî |
| üèîÔ∏è **Performance** | ‚Äî | ‚Äî | ‚Äî | ‚Äî | k6 baseline |
| üñ•Ô∏è **Interface** | ‚Äî | ‚Äî | ‚Äî | ‚Äî | Vitest render √ó 3 |

> **Lecture** : chaque cellule = une action concr√®te. Les colonnes se lisent comme un sprint. Les lignes se lisent comme un th√®me de comp√©tence √† pr√©senter en entretien.

---

## 7. Verdict

### La proposition Codex est-elle bonne ?

**Oui, la structure en 4 niveaux et le ratio 70/20/10 sont solides et standards.**  
C'est un cadre reconnu (Test Pyramid de Mike Cohn, adapt√© microservices).

### Ce qui manque dans la proposition :

| Gap | Impact |
|---|---|
| **Phase 0 absente** ‚Äî aucune fondation test dans 5/6 services | Niveaux 1-3 impossibles sans √ßa |
| **`build-and-push` n'ex√©cute aucun test** | Le pipeline build ne d√©tecte rien, m√™me les tests existants ne tournent qu'en local |
| **Granularit√© Niveau 3 trop large** | Test full-chain = E2E d√©guis√©, pr√©f√©rer des tests par segment |
| **Frontend oubli√©** | 0 test, m√™me un render smoke aurait de la valeur |
| **Pas de mention de documentation des cl√©s Redis** | Les tests d'int√©gration inter-services n√©cessitent un contrat de cl√©s partag√© |
| **Pas de priorisation d'impl√©mentation** | Phase 0 ‚Üí 1 ‚Üí 4(E2E) ‚Üí 3 ‚Üí 2, pas 1 ‚Üí 2 ‚Üí 3 ‚Üí 4 |

### Recommandation finale

Impl√©menter dans cet ordre :
1. **Phase 0** ‚Äî fondations + `mvn test` dans CI (**priorit√© maximale**, quick win)
2. **Phase 1** ‚Äî context smoke par service
3. **Phase 3 partielle** ‚Äî 2 checks applicatifs dans le smoke E2E existant
4. **Phase 2** ‚Äî Testcontainers Redis (data-path)
5. **Phase 3 compl√®te** ‚Äî contract HTTP
6. **Phase 4** ‚Äî frontend Vitest

Le tout est faisable en **~20h de travail incr√©mental**, r√©parti sur 3-4 sprints.

---

## 8. DoD pour l'issue "Test Strategy v1.1"

Si tu cr√©es l'issue, voici le DoD propos√© :

**Phase 0 ‚Äî Fondations (quick wins)** :
- [ ] `spring-boot-starter-test` dans les pom.xml de ingester et processor
- [ ] `mvn test` (ou `mvn verify -DskipITs`) ex√©cut√© dans `build-and-push.yml`
- [ ] Hadolint dans `build-and-push.yml`
- [ ] kubeconform dans `ci-k8s.yml`
- [ ] `.github/dependabot.yml` configur√© (maven + npm + github-actions)

**Phase 1 ‚Äî Context smoke + static analysis** :
- [ ] 1 test `@SpringBootTest.contextLoads()` par service Java (3 services)
- [ ] Checkstyle + SpotBugs dans les pom.xml des services Java
- [ ] ESLint + Prettier configur√©s dans le frontend
- [ ] Trivy fs (dependency scan) dans `build-and-push.yml`
- [ ] 1 check applicatif ajout√© au smoke test CI (`/api/flights` ‚Üí 200 + JSON)

**Phase 2 ‚Äî Int√©gration** :
- [ ] Testcontainers Redis dans au moins 1 service (ingester ou processor)
- [ ] Trivy image scan dans `build-and-push.yml`
- [ ] `docs/events-schemas/redis-keys.md` documentant les cl√©s Redis partag√©es

**Phase 3 ‚Äî Contract + frontend** :
- [ ] Contract HTTP test (MockWebServer ou payload JSON) dans au moins 1 service
- [ ] 1 test frontend Vitest (au moins un composant rend sans crash)

**Phase 4 ‚Äî Excellence (optionnel, fort impact entretien)** :
- [ ] Script k6 baseline avec thresholds (p95 < 500ms)
- [ ] Rollback validation dans le smoke test CI
